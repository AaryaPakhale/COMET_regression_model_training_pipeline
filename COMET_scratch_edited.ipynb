{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9gksiy4LrCN",
        "outputId": "cf08d811-30cd-4cd2-9b23-afb54aa4dd62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Collecting entmax\n",
            "  Downloading entmax-1.3-py3-none-any.whl.metadata (348 bytes)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from entmax) (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->entmax) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->entmax) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->entmax) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->entmax) (1.3.0)\n",
            "Downloading entmax-1.3-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: entmax\n",
            "Successfully installed entmax-1.3\n",
            "Collecting peft\n",
            "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.3.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.4)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.32.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.20)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Downloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: peft\n",
            "Successfully installed peft-0.12.0\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.17.5-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.12.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.17.5-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.12.0-py2.py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.12.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.5\n",
            "Collecting unbabel-comet\n",
            "  Downloading unbabel_comet-2.2.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: entmax<2.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.23.5)\n",
            "Collecting jsonargparse==3.13.1 (from unbabel-comet)\n",
            "  Downloading jsonargparse-3.13.1-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.1.4)\n",
            "Collecting protobuf<5.0.0,>=4.24.4 (from unbabel-comet)\n",
            "  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting pytorch-lightning<3.0.0,>=2.0.0 (from unbabel-comet)\n",
            "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting sacrebleu<3.0.0,>=2.0.0 (from unbabel-comet)\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy<2.0.0,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece<0.2.0,>=0.1.96 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.3.1+cu121)\n",
            "Collecting torchmetrics<0.11.0,>=0.10.2 (from unbabel-comet)\n",
            "  Downloading torchmetrics-0.10.3-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: transformers<5.0,>=4.17 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (4.42.4)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet) (2024.1)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet)\n",
            "  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting portalocker (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.9.0)\n",
            "Collecting colorama (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (4.9.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->unbabel-comet) (12.6.20)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.19.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (71.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->unbabel-comet) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (4.0.3)\n",
            "Downloading unbabel_comet-2.2.2-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonargparse-3.13.1-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: protobuf, portalocker, lightning-utilities, jsonargparse, colorama, sacrebleu, torchmetrics, pytorch-lightning, unbabel-comet\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 jsonargparse-3.13.1 lightning-utilities-0.11.6 portalocker-2.10.1 protobuf-4.25.4 pytorch-lightning-2.3.3 sacrebleu-2.4.2 torchmetrics-0.10.3 unbabel-comet-2.2.2\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ],
      "source": [
        "# !pip install accelerate\n",
        "!pip install bitsandbytes\n",
        "!pip install transformers\n",
        "!pip install entmax\n",
        "!pip install peft\n",
        "!pip install wandb\n",
        "!pip install unbabel-comet\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83d__swRgkrO",
        "outputId": "488c6f87-ad13-407f-ac59-4d86d788b482"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:bitsandbytes.cextension:The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "from typing import Any, Dict, List, Union, Optional\n",
        "import torch\n",
        "import bitsandbytes as bnb\n",
        "from comet import load_from_checkpoint, download_model\n",
        "\n",
        "from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n",
        "from functools import partial\n",
        "import torch.optim as optim\n",
        "from transformers import XLMRobertaModel, XLMRobertaTokenizer, XLMRobertaConfig, AutoModelForMaskedLM\n",
        "\n",
        "from transformers import AlbertTokenizer, AlbertModel, AlbertConfig, AutoModelForMaskedLM\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Parameter, ParameterList\n",
        "from entmax import sparsemax\n",
        "\n",
        "from transformers import AdamW, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n",
        "import argparse\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "085hfNuQgp-u"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dataset_path):\n",
        "    df = pd.read_csv(dataset_path, encoding='utf-8')\n",
        "    selected_columns = [\"src\", \"mt\", \"ref\",\"score_mqm\"]\n",
        "    df = df[selected_columns]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7tprTI7guWk"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(df, model, tokenizer, max_length: int):\n",
        "    # Tokenize and encode each column\n",
        "    for column in [\"src\", \"mt\", \"ref\"]:\n",
        "        df[f\"{column}_tokens\"] = df[f\"{column}\"].apply(\n",
        "            lambda x: tokenizer.encode(x, truncation=True, padding='max_length', max_length=max_length)\n",
        "        )\n",
        "\n",
        "    # Create tensors from the tokenized columns\n",
        "    input_ids = {\n",
        "        \"input_ids_src\": torch.tensor(df[\"src_tokens\"].tolist(), dtype=torch.long),\n",
        "        \"input_ids_mt\": torch.tensor(df[\"mt_tokens\"].tolist(), dtype=torch.long),\n",
        "        \"input_ids_ref\": torch.tensor(df[\"ref_tokens\"].tolist(), dtype=torch.long),\n",
        "        \"score_mqm\": torch.tensor(df[\"score_mqm\"].tolist(), dtype=torch.float),\n",
        "    }\n",
        "\n",
        "    # Create TensorDataset\n",
        "    dataset = TensorDataset(\n",
        "        input_ids[\"input_ids_src\"],\n",
        "        input_ids[\"input_ids_mt\"],\n",
        "        input_ids[\"input_ids_ref\"],\n",
        "        input_ids[\"score_mqm\"]\n",
        "    )\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6eIIy6kgzhK"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "\n",
        "class DataCollatorWithPadding:\n",
        "    tokenizer: AutoTokenizer\n",
        "\n",
        "    def __call__(self, features: List[tuple]) -> Dict[str, torch.Tensor]:\n",
        "\n",
        "        # Extract and pad input_ids_src\n",
        "        input_ids_src_features = [{\"input_ids\": feature[0].tolist()} for feature in features]\n",
        "        input_ids_src_batch = self.tokenizer.pad(input_ids_src_features, return_tensors=\"pt\")\n",
        "        input_ids_src = input_ids_src_batch[\"input_ids\"]\n",
        "\n",
        "        # Extract and pad input_ids_mt\n",
        "        input_ids_mt_features = [{\"input_ids\": feature[1].tolist()} for feature in features]\n",
        "        input_ids_mt_batch = self.tokenizer.pad(input_ids_mt_features, return_tensors=\"pt\")\n",
        "        input_ids_mt = input_ids_mt_batch[\"input_ids\"]\n",
        "\n",
        "        # Extract and pad input_ids_ref\n",
        "        input_ids_ref_features = [{\"input_ids\": feature[2].tolist()} for feature in features]\n",
        "        input_ids_ref_batch = self.tokenizer.pad(input_ids_ref_features, return_tensors=\"pt\")\n",
        "        input_ids_ref = input_ids_ref_batch[\"input_ids\"]\n",
        "\n",
        "        # Extract score_mqm and convert to tensor\n",
        "        scores_mqm = torch.tensor([feature[3].item() for feature in features], dtype=torch.float)\n",
        "\n",
        "        # Create the batch\n",
        "        batch = {\n",
        "            "input_ids_src": input_ids_src,\n",
        "            "input_ids_mt": input_ids_mt,\n",
        "            "input_ids_ref": input_ids_ref,\n",
        "            "scores_mqm": scores_mqm\n",
        "        }\n",
        "        return batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhPMD_njg3db"
      },
      "outputs": [],
      "source": [
        "def create_dataloader(dataset_train, dataset_val, tokenizer, train_batch_size, val_batch_size):\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "    dataloader_train = DataLoader(dataset_train, batch_size=train_batch_size, shuffle=True, collate_fn=data_collator)\n",
        "    dataloader_val = DataLoader(dataset_val, batch_size=val_batch_size, shuffle=False, collate_fn=data_collator)\n",
        "    return dataloader_train, dataloader_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QRMGRNJg51c"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name, random_init=False, hidden_dropout=0.1):\n",
        "    if random_init:\n",
        "        print(\"Randomly initializing the model\")\n",
        "        config = AlbertConfig.from_pretrained(model_name)\n",
        "        config.hidden_dropout_prob = hidden_dropout\n",
        "\n",
        "        model = AlbertModel(config)\n",
        "    else:\n",
        "        model = AutoModelForMaskedLM.from_pretrained(model_name, hidden_dropout_prob=hidden_dropout)\n",
        "\n",
        "    # model.to(\"cuda:0\")\n",
        "    model.config.forced_decoder_ids = None\n",
        "    model.config.suppress_tokens = []\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, keep_accents=True, max_length=512)\n",
        "\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waRvR-i_2RA_"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# def load_model(model_name, random_init=False, hidden_dropout=0.1):\n",
        "#     if random_init:\n",
        "#         print(\"Randomly initializing the model\")\n",
        "#         config = AutoConfig.from_pretrained(model_name)\n",
        "#         config.dropout = hidden_dropout\n",
        "\n",
        "#         model = AutoModelForSeq2SeqLM(config)\n",
        "#     else:\n",
        "#         model = AutoModelForSeq2SeqLM.from_pretrained(model_name, dropout=hidden_dropout)\n",
        "\n",
        "#     # model.to(\"cuda:0\")\n",
        "#     model.config.forced_decoder_ids = None\n",
        "#     model.config.suppress_tokens = []\n",
        "#     tokenizer = AutoTokenizer.from_pretrained(model_name, keep_accents=True, max_length=512)\n",
        "\n",
        "#     return model, tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGMHKFCOTRqf"
      },
      "outputs": [],
      "source": [
        "# def load_model(model_name, random_init=False, hidden_dropout=0.1):\n",
        "#   model_path = download_model(\"Unbabel/wmt22-cometkiwi-da\")\n",
        "#   model = load_from_checkpoint(model_path)\n",
        "\n",
        "#   # model.config.dropout = hidden_dropout\n",
        "#   # model.config.forced_decoder_ids = None\n",
        "#   # model.config.suppress_tokens = []\n",
        "\n",
        "#   tokenizer = AutoTokenizer.from_pretrained(model_name, keep_accents=True, max_length=512)\n",
        "#   return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEB3A_IHg9sd"
      },
      "outputs": [],
      "source": [
        "class LayerwiseAttention(torch.nn.Module):\n",
        "            def __init__(\n",
        "                self,\n",
        "                num_layers: int,\n",
        "                layer_norm: bool = False,\n",
        "                layer_weights: Optional[List[int]] = None,\n",
        "                dropout: float = 0.1,\n",
        "                layer_transformation: str = \"softmax\",\n",
        "            ) -> None:\n",
        "                super(LayerwiseAttention, self).__init__()\n",
        "                self.num_layers = num_layers\n",
        "                self.layer_norm = layer_norm\n",
        "                self.dropout = dropout\n",
        "\n",
        "                self.transform_fn = torch.softmax\n",
        "                if layer_transformation == \"sparsemax\":\n",
        "                    self.transform_fn = sparsemax\n",
        "\n",
        "                if layer_weights is None:\n",
        "                    layer_weights = [0.0] * num_layers\n",
        "                elif len(layer_weights) != num_layers:\n",
        "                    raise Exception(\n",
        "                        \"Length of layer_weights {} differs \\\n",
        "                        from num_layers {}\".format(\n",
        "                            layer_weights, num_layers\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "                self.scalar_parameters = ParameterList(\n",
        "                    [\n",
        "                        Parameter(\n",
        "                            torch.FloatTensor([layer_weights[i]]),\n",
        "                            requires_grad=True,\n",
        "                        )\n",
        "                        for i in range(num_layers)\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "                self.gamma = Parameter(torch.FloatTensor([1.0]), requires_grad=True)\n",
        "\n",
        "                if self.dropout:\n",
        "                    dropout_mask = torch.zeros(len(self.scalar_parameters))\n",
        "                    dropout_fill = torch.empty(len(self.scalar_parameters)).fill_(-1e20)\n",
        "                    self.register_buffer(\"dropout_mask\", dropout_mask)\n",
        "                    self.register_buffer(\"dropout_fill\", dropout_fill)\n",
        "\n",
        "            def forward(\n",
        "                self,\n",
        "                tensors: List[torch.Tensor],  # pylint: disable=arguments-differ\n",
        "                mask: torch.Tensor = None,\n",
        "            ) -> torch.Tensor:\n",
        "                if len(tensors) != self.num_layers:\n",
        "                    raise Exception(\n",
        "                        \"{} tensors were passed, but the module was initialized to \\\n",
        "                        mix {} tensors.\".format(\n",
        "                            len(tensors), self.num_layers\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "                def _layer_norm(tensor, broadcast_mask, mask):\n",
        "                    tensor_masked = tensor * broadcast_mask\n",
        "                    batch_size, _, input_dim = tensors[0].size()\n",
        "\n",
        "                    # mean for each sentence\n",
        "                    num_elements_not_masked = mask.sum(1) * input_dim\n",
        "                    mean = tensor_masked.view(batch_size, -1).sum(1)\n",
        "                    mean = (mean / num_elements_not_masked).view(batch_size, 1, 1)\n",
        "\n",
        "                    variance = (((tensor_masked - mean) * broadcast_mask) ** 2).view(\n",
        "                        batch_size, -1\n",
        "                    ).sum(1) / num_elements_not_masked\n",
        "                    normalized_tensor = (tensor - mean) / torch.sqrt(variance + 1e-12).view(\n",
        "                        batch_size, 1, 1\n",
        "                    )\n",
        "                    return normalized_tensor\n",
        "\n",
        "                if len([parameter for parameter in self.scalar_parameters]) != self.num_layers:\n",
        "                    weights = torch.tensor(self.weights, device=tensors[0].device)\n",
        "                    gamma = torch.tensor(self.gamma_value, device=tensors[0].device)\n",
        "                else:\n",
        "                    weights = torch.cat([parameter for parameter in self.scalar_parameters])\n",
        "                    gamma = self.gamma\n",
        "\n",
        "                if self.training and self.dropout:\n",
        "                    weights = torch.where(\n",
        "                        self.dropout_mask.uniform_() > self.dropout, weights, self.dropout_fill\n",
        "                    )\n",
        "\n",
        "                normed_weights = self.transform_fn(weights, dim=0)\n",
        "                normed_weights = torch.split(normed_weights, split_size_or_sections=1)\n",
        "\n",
        "                if not self.layer_norm:\n",
        "                    pieces = []\n",
        "                    for weight, tensor in zip(normed_weights, tensors):\n",
        "                        pieces.append(weight * tensor)\n",
        "                    return gamma * sum(pieces)\n",
        "\n",
        "                else:\n",
        "                    mask_float = mask.float()\n",
        "                    broadcast_mask = mask_float.unsqueeze(-1)\n",
        "\n",
        "                    pieces = []\n",
        "                    for weight, tensor in zip(normed_weights, tensors):\n",
        "                        pieces.append(weight * _layer_norm(tensor, broadcast_mask, mask_float))\n",
        "                    return gamma * sum(pieces)\n",
        "\n",
        "\n",
        "class SentencePooling(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(SentencePooling, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "    def forward(self, token_embeddings, input_ids_attention_mask):\n",
        "        # token_embeddings shape: (batch_size, num_tokens, embedding_dim)\n",
        "\n",
        "        # input_ids_attention_mask shape: (batch_size, num_tokens)\n",
        "\n",
        "        sentence_embeddings = token_embeddings[:, 1:-1, :]\n",
        "        input_ids_attention_mask = input_ids_attention_mask[:, 1:-1]\n",
        "        # Unsqueeze input_ids_attention_mask to match the dimensions of sentence_embeddings\n",
        "        input_ids_attention_mask = input_ids_attention_mask.unsqueeze(-1)\n",
        "        masked_hidden_states = sentence_embeddings * input_ids_attention_mask\n",
        "        sum_attention_mask = input_ids_attention_mask.sum(dim=1)\n",
        "        final_pooled = masked_hidden_states.sum(dim=1) / sum_attention_mask\n",
        "\n",
        "        return final_pooled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvcFdeoK2SaX"
      },
      "outputs": [],
      "source": [
        "class XLMRForRegression(nn.Module):\n",
        "    def __init__(self, tokenizer, batch_size, pretrained_model_name='ai4bharat/IndicBERTv2-MLM-only', pool_output=True, pooling_logic=None, ):\n",
        "        super(XLMRForRegression, self).__init__()\n",
        "        self.model = AutoModel.from_pretrained(pretrained_model_name)\n",
        "        self.tokenizer= tokenizer\n",
        "        self.pool_output = pool_output\n",
        "        self.pooling_logic = pooling_logic\n",
        "        self.batch_size= batch_size\n",
        "\n",
        "        # if pooling_logic == \"layerwise_attention_mean\":\n",
        "        #     if hasattr(self.model, 'config'):\n",
        "        #         hidden_size = 4 * self.model.config.hidden_size + 2 * self.model.config.hidden_size**2\n",
        "        #     else:\n",
        "        #         # Manually specify the hidden size if the model does not have a config attribute\n",
        "        #         hidden_size = 4 * 1024 + 2 * 1024**2  # Adjust the 1024 to the appropriate size for your model\n",
        "        # else:\n",
        "        #     if hasattr(self.model, 'config'):\n",
        "        #         hidden_size = 3 * self.model.config.hidden_size\n",
        "        #     else:\n",
        "        #         # Manually specify the hidden size if the model does not have a config attribute\n",
        "        #         hidden_size = 3 * 1024  # Adjust the 1024 to the appropriate size for your model\n",
        "\n",
        "        # self.linear = nn.Linear(hidden_size, 1)\n",
        "\n",
        "        if pooling_logic==\"layerwise_attention_mean\":\n",
        "          hidden_size = 4 * self.model.config.hidden_size + 2 * self.model.config.hidden_size**2\n",
        "        else:\n",
        "          hidden_size = 3 * self.model.config.hidden_size\n",
        "\n",
        "        self.linear = nn.Linear(hidden_size, 1)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids_src, input_ids_mt, input_ids_ref):\n",
        "\n",
        "        # Calculate padding tokens and Encode source, MT, and reference sequences\n",
        "        input_ids_src_attention_mask= input_ids_src.ne(self.tokenizer.pad_token_id)\n",
        "        input_ids_mt_attention_mask= input_ids_mt.ne(self.tokenizer.pad_token_id)\n",
        "        input_ids_ref_attention_mask= input_ids_ref.ne(self.tokenizer.pad_token_id)\n",
        "\n",
        "        src_outputs = self.model(input_ids_src, input_ids_src_attention_mask, output_hidden_states=True)\n",
        "        mt_outputs = self.model(input_ids_mt, input_ids_mt_attention_mask, output_hidden_states=True)\n",
        "        ref_outputs = self.model(input_ids_ref, input_ids_ref_attention_mask, output_hidden_states=True)\n",
        "\n",
        "        # if self.pool_output:\n",
        "        if self.pooling_logic == \"layerwise_attention_mean\":\n",
        "\n",
        "          # Extract hidden states from model outputs\n",
        "          src_hidden_states = src_outputs.hidden_states\n",
        "          mt_hidden_states = mt_outputs.hidden_states\n",
        "          ref_hidden_states = ref_outputs.hidden_states\n",
        "\n",
        "          # Initialize LayerwiseAttention with the number of layers from hidden states\n",
        "          layerwise_attention = LayerwiseAttention(num_layers=len(src_hidden_states))\n",
        "\n",
        "          # Compute pooled token embeddings\n",
        "          src_pooled_token_embeddings = layerwise_attention(src_hidden_states)\n",
        "          mt_pooled_token_embeddings = layerwise_attention(mt_hidden_states)\n",
        "          ref_pooled_token_embeddings = layerwise_attention(ref_hidden_states)\n",
        "\n",
        "          # Compute sentence embeddings\n",
        "          sentence_pooling = SentencePooling(self.model.config.hidden_size)\n",
        "\n",
        "          src_pooled = sentence_pooling(src_pooled_token_embeddings, input_ids_src_attention_mask)\n",
        "          mt_pooled = sentence_pooling(mt_pooled_token_embeddings, input_ids_mt_attention_mask)\n",
        "          ref_pooled = sentence_pooling(ref_pooled_token_embeddings, input_ids_ref_attention_mask)\n",
        "\n",
        "          mt_src_matmul = torch.matmul(mt_pooled.unsqueeze(-1), src_pooled.unsqueeze(1)).view(self.batch_size, -1)\n",
        "          mt_ref_matmul = torch.matmul(mt_pooled.unsqueeze(-1), ref_pooled.unsqueeze(1)).view(self.batch_size, -1)\n",
        "\n",
        "          # Concatenate pooled representations\n",
        "          combined_pooled = torch.cat([\n",
        "              mt_pooled,\n",
        "              ref_pooled,\n",
        "              mt_src_matmul,\n",
        "              mt_ref_matmul,\n",
        "              torch.abs(mt_pooled - src_pooled),\n",
        "              torch.abs(mt_pooled - ref_pooled)\n",
        "          ], dim=1)\n",
        "\n",
        "        elif self.pooling_logic== \"cls_token\":\n",
        "\n",
        "          # Pool the outputs (taking the <s> token representation)\n",
        "          src_pooled = src_outputs.last_hidden_state[:, 0, :]\n",
        "          mt_pooled = mt_outputs.last_hidden_state[:, 0, :]\n",
        "          ref_pooled = ref_outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "          combined_pooled = torch.cat([\n",
        "              mt_pooled,\n",
        "              ref_pooled,\n",
        "              src_pooled\n",
        "          ], dim=1)\n",
        "\n",
        "        elif self.pooling_logic== \"mean\":\n",
        "          sentence_pooling = SentencePooling(self.model.config.hidden_size)\n",
        "          src_pooled = sentence_pooling(src_pooled_token_embeddings, input_ids_src_attention_mask)\n",
        "          mt_pooled = sentence_pooling(mt_pooled_token_embeddings, input_ids_mt_attention_mask)\n",
        "          ref_pooled = sentence_pooling(ref_pooled_token_embeddings, input_ids_ref_attention_mask)\n",
        "\n",
        "          combined_pooled = torch.cat([\n",
        "              mt_pooled,\n",
        "              ref_pooled,\n",
        "              src_pooled,\n",
        "          ], dim=1)\n",
        "\n",
        "\n",
        "        # Pass through linear layer\n",
        "        score = self.linear(combined_pooled)\n",
        "        return score\n",
        "\n",
        "    def save_pretrained(self, save_path):\n",
        "        self.model.save_pretrained(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LSlJbk1hEPG"
      },
      "outputs": [],
      "source": [
        "def convert_to_lora(model, r=32, lora_alpha=64, target_modules=[], lora_dropout=0.05):\n",
        "    config = LoraConfig(r=r, lora_alpha=lora_alpha, target_modules=target_modules, lora_dropout=lora_dropout)\n",
        "\n",
        "    model = get_peft_model(model, config)\n",
        "    model.print_trainable_parameters()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xx3QgK-0hIko"
      },
      "outputs": [],
      "source": [
        "def get_optimizer_scheduler(model, lr, epochs, dataloader_train, gradient_accumulation_steps=1, use_8bit_adam=False):\n",
        "    if use_8bit_adam:\n",
        "        print(\"Using 8 bit adam\")\n",
        "        optimizer = bnb.optim.AdamW8bit(model.parameters(), lr=lr)\n",
        "    else:\n",
        "        optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    num_steps = int(len(dataloader_train) / gradient_accumulation_steps) * epochs\n",
        "    warmup_steps = int(num_steps * 0.1)\n",
        "\n",
        "    print(\"Total number of training steps is:\", num_steps, \"and warmup steps is:\", warmup_steps)\n",
        "\n",
        "    scheduler = get_cosine_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=warmup_steps,\n",
        "        num_training_steps=num_steps,\n",
        "        num_cycles=0.5\n",
        "    )\n",
        "\n",
        "    return optimizer, scheduler, num_steps, warmup_steps\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sbP9U5r49kW1"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from transformers import AdamW\n",
        "# from torch.optim.lr_scheduler import CyclicLR\n",
        "\n",
        "# def get_optimizer_scheduler(model, lr, epochs, dataloader_train, gradient_accumulation_steps=1, use_8bit_adam=False):\n",
        "#     if use_8bit_adam:\n",
        "#         print(\"Using 8 bit adam\")\n",
        "#         optimizer = bnb.optim.AdamW8bit(model.parameters(), lr=lr)\n",
        "#     else:\n",
        "#         optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "#     num_steps = int(len(dataloader_train) / gradient_accumulation_steps) * epochs\n",
        "\n",
        "#     # Define the minimum and maximum learning rates\n",
        "#     base_lr = lr * 1e-4\n",
        "#     max_lr = lr * 1e-1\n",
        "\n",
        "#     print(\"Total number of training steps is:\", num_steps)\n",
        "\n",
        "#     scheduler = CyclicLR(\n",
        "#         optimizer,\n",
        "#         base_lr=base_lr,\n",
        "#         max_lr=max_lr,\n",
        "#         step_size_up=num_steps // 10,  # Adjust the step size according to your needs\n",
        "#         mode='triangular',  # You can choose 'triangular', 'triangular2', or 'exp_range'\n",
        "#         cycle_momentum=False  # Set to True if you are using optimizers that support momentum\n",
        "#     )\n",
        "\n",
        "#     return optimizer, scheduler, num_steps\n",
        "\n",
        "# # Example usage\n",
        "# # model = YourModel()\n",
        "# # dataloader_train = YourDataLoader()\n",
        "# # lr = 1e-3\n",
        "# # epochs = 10\n",
        "# # optimizer, scheduler, num_steps = get_optimizer_scheduler(model, lr, epochs, dataloader_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NeoTROu-hM2N"
      },
      "outputs": [],
      "source": [
        "def train(model, encoder, dataloader_train, dataloader_val, optimizer, scheduler, criterion, epochs=5, eval_every_n_steps=50, max_no_improvement_evals=3, save_path=None, is_deepspeed=False):\n",
        "\n",
        "    time_to_stop = False\n",
        "    no_improvement_evals = 0\n",
        "    previous_eval_loss = 10000\n",
        "    curr_step = 0\n",
        "    num_steps = len(dataloader_train) * epochs\n",
        "\n",
        "    wandb.config.update({\n",
        "        \"epochs\": epochs,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        \"batch_size\": dataloader_train.batch_size,\n",
        "        \"train_steps_per_epoch\": len(dataloader_train),\n",
        "        \"eval_every_n_steps\": eval_every_n_steps,\n",
        "        \"max_no_improvement_evals\": max_no_improvement_evals\n",
        "    })\n",
        "\n",
        "    with tqdm(total=num_steps) as progress:\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"Epoch {epoch + 1} out of {epochs} epochs\")\n",
        "            inner_step = 0\n",
        "\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "\n",
        "            for batch in dataloader_train:\n",
        "                input_ids_src, input_ids_mt, input_ids_ref, score_mqm = batch\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(input_ids_src, input_ids_mt, input_ids_ref).squeeze()\n",
        "                loss = criterion(outputs, score_mqm)\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                inner_step += 1\n",
        "                curr_step += 1\n",
        "\n",
        "                if curr_step % eval_every_n_steps == 0:\n",
        "                    print(\"Evaluation step\")\n",
        "                    with torch.no_grad():\n",
        "                        model.eval()\n",
        "                        predictions = []\n",
        "                        actuals = []\n",
        "\n",
        "                        final_loss = 0\n",
        "                        final_correlation = 0\n",
        "                        num_eval_batches = len(dataloader_val)\n",
        "\n",
        "                        for eval_batch in tqdm(dataloader_val):\n",
        "                            input_ids_src, input_ids_mt, input_ids_ref, score_mqm = eval_batch\n",
        "                            eval_outputs = model(input_ids_src, input_ids_mt, input_ids_ref).squeeze()\n",
        "\n",
        "                            predictions.extend(eval_outputs.tolist())\n",
        "                            actuals.extend(score_mqm.tolist())\n",
        "\n",
        "                            eval_loss = criterion(torch.tensor(predictions), torch.tensor(actuals))\n",
        "                            final_loss += eval_loss.item()\n",
        "\n",
        "                            correlation_matrix = np.corrcoef(torch.tensor(predictions), torch.tensor(actuals))\n",
        "                            pearson_correlation = correlation_matrix[0, 1]\n",
        "                            final_correlation += pearson_correlation\n",
        "\n",
        "                        final_loss /= num_eval_batches\n",
        "                        final_correlation /= num_eval_batches\n",
        "\n",
        "                        print(f\"Eval loss after {curr_step} steps is {final_loss:.4f}\")\n",
        "                        print(f\"Final Correlation after {curr_step} steps is {final_correlation:.4f}\")\n",
        "\n",
        "                        # Log to wandb\n",
        "                        wandb.log({\n",
        "                            \"Eval Loss\": final_loss,\n",
        "                            \"Pearson Correlation\": final_correlation,\n",
        "                            \"Step\": curr_step\n",
        "                        })\n",
        "\n",
        "                        if final_loss < previous_eval_loss:\n",
        "                            previous_eval_loss = final_loss\n",
        "                            no_improvement_evals = 0\n",
        "                            print(\"Saving model since validation loss reduced\")\n",
        "                            model.save_pretrained(save_path)\n",
        "                            encoder.save_pretrained(save_path)\n",
        "                        else:\n",
        "                            no_improvement_evals += 1\n",
        "                            print(f\"No improvement in eval loss for {no_improvement_evals} evaluations\")\n",
        "                            if no_improvement_evals >= max_no_improvement_evals:\n",
        "                                print(f\"No improvement in eval loss for {no_improvement_evals} evaluations and max no improvement evals is {max_no_improvement_evals}, so stopping\")\n",
        "                                time_to_stop = True\n",
        "\n",
        "                    if time_to_stop:\n",
        "                        break\n",
        "\n",
        "                    model.train()\n",
        "\n",
        "                if curr_step % 10 == 0:\n",
        "                    print(f\"Loss at step {curr_step} is {loss.item():.4f}\")\n",
        "                    wandb.log({\n",
        "                        \"Train Loss\": loss.item(),\n",
        "                        \"Step\": curr_step\n",
        "                    })\n",
        "\n",
        "                progress.update(1)\n",
        "\n",
        "            avg_loss = total_loss / len(dataloader_train)\n",
        "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "            wandb.log({\n",
        "                \"Epoch Loss\": avg_loss,\n",
        "                \"Epoch\": epoch + 1\n",
        "            })\n",
        "\n",
        "            if time_to_stop:\n",
        "                break\n",
        "\n",
        "        if not time_to_stop:  # Eval on the final checkpoint to see if it's any better or not.\n",
        "            print(\"Model has not converged till the last batch so doing a final evaluation.\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                predictions = []\n",
        "                actuals = []\n",
        "\n",
        "                model.eval()\n",
        "                final_loss = 0\n",
        "                final_correlation = 0\n",
        "                num_eval_batches = len(dataloader_val)\n",
        "\n",
        "                for eval_batch in tqdm(dataloader_val):\n",
        "                    input_ids_src, input_ids_mt, input_ids_ref, score_mqm = eval_batch\n",
        "                    eval_outputs = model(input_ids_src, input_ids_mt, input_ids_ref).squeeze()\n",
        "\n",
        "                    predictions.extend(eval_outputs.tolist())\n",
        "                    actuals.extend(score_mqm.tolist())\n",
        "\n",
        "                    eval_loss = criterion(torch.tensor(predictions), torch.tensor(actuals))\n",
        "                    final_loss += eval_loss.item()\n",
        "\n",
        "                    correlation_matrix = np.corrcoef(torch.tensor(predictions), torch.tensor(actuals))\n",
        "                    pearson_correlation = correlation_matrix[0, 1]\n",
        "                    final_correlation += pearson_correlation\n",
        "\n",
        "                final_loss /= num_eval_batches\n",
        "                final_correlation /= num_eval_batches\n",
        "\n",
        "                print(f\"Eval loss after {curr_step} steps is {final_loss:.4f}\")\n",
        "                print(f\"Final Correlation after {curr_step} steps is {final_correlation:.4f}\")\n",
        "\n",
        "                # Log to wandb\n",
        "                wandb.log({\n",
        "                    \"Final Eval Loss\": final_loss,\n",
        "                    \"Final Pearson Correlation\": final_correlation\n",
        "                })\n",
        "\n",
        "                if final_loss < previous_eval_loss:\n",
        "                    print(\"Saving final model since validation loss reduced\")\n",
        "                    model.save_pretrained(save_path)\n",
        "                    encoder.save_pretrained(save_path)\n",
        "                else:\n",
        "                    print(\"No improvement in eval loss even after the final batch.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, encoder, dataloader, criterion):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    final_loss = 0\n",
        "    final_correlation = 0\n",
        "    num_eval_batches = len(dataloader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for eval_batch in tqdm(dataloader):\n",
        "            input_ids_src, input_ids_mt, input_ids_ref, score_mqm = eval_batch\n",
        "            eval_outputs = model(input_ids_src, input_ids_mt, input_ids_ref).squeeze()\n",
        "\n",
        "            predictions.extend(eval_outputs.tolist())\n",
        "            actuals.extend(score_mqm.tolist())\n",
        "\n",
        "            eval_loss = criterion(torch.tensor(predictions), torch.tensor(actuals))\n",
        "            final_loss += eval_loss.item()\n",
        "\n",
        "            correlation_matrix = np.corrcoef(torch.tensor(predictions), torch.tensor(actuals))\n",
        "            pearson_correlation = correlation_matrix[0, 1]\n",
        "            final_correlation += pearson_correlation\n",
        "\n",
        "        final_loss /= num_eval_batches\n",
        "        final_correlation /= num_eval_batches\n",
        "\n",
        "    return final_loss, final_correlation\n",
        "\n",
        "def train(model, encoder, dataloader_train, dataloader_val, dataloader_test, optimizer, scheduler, criterion, epochs=5, eval_every_n_steps=50, max_no_improvement_evals=3, save_path=None, is_deepspeed=False):\n",
        "\n",
        "    time_to_stop = False\n",
        "    no_improvement_evals = 0\n",
        "    previous_eval_loss = 10000\n",
        "    curr_step = 0\n",
        "    num_steps = len(dataloader_train) * epochs\n",
        "\n",
        "    wandb.config.update({\n",
        "        \"epochs\": epochs,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        \"batch_size\": dataloader_train.batch_size,\n",
        "        \"train_steps_per_epoch\": len(dataloader_train),\n",
        "        \"eval_every_n_steps\": eval_every_n_steps,\n",
        "        \"max_no_improvement_evals\": max_no_improvement_evals\n",
        "    })\n",
        "\n",
        "    with tqdm(total=num_steps) as progress:\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"Epoch {epoch + 1} out of {epochs} epochs\")\n",
        "            inner_step = 0\n",
        "\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "\n",
        "            for batch in dataloader_train:\n",
        "                input_ids_src, input_ids_mt, input_ids_ref, score_mqm = batch\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(input_ids_src, input_ids_mt, input_ids_ref).squeeze()\n",
        "                loss = criterion(outputs, score_mqm)\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                inner_step += 1\n",
        "                curr_step += 1\n",
        "\n",
        "                if curr_step % eval_every_n_steps == 0:\n",
        "                    print(\"Evaluation step\")\n",
        "                    final_loss, final_correlation = evaluate(model, encoder, dataloader_val, criterion)\n",
        "\n",
        "                    print(f\"Eval loss after {curr_step} steps is {final_loss:.4f}\")\n",
        "                    print(f\"Final Correlation after {curr_step} steps is {final_correlation:.4f}\")\n",
        "\n",
        "                    # Log to wandb\n",
        "                    wandb.log({\n",
        "                        \"Eval Loss\": final_loss,\n",
        "                        \"Pearson Correlation\": final_correlation,\n",
        "                        \"Step\": curr_step\n",
        "                    })\n",
        "\n",
        "                    if final_loss < previous_eval_loss:\n",
        "                        previous_eval_loss = final_loss\n",
        "                        no_improvement_evals = 0\n",
        "                        print(\"Saving model since validation loss reduced\")\n",
        "                        model.save_pretrained(save_path)\n",
        "                        encoder.save_pretrained(save_path)\n",
        "                    else:\n",
        "                        no_improvement_evals += 1\n",
        "                        print(f\"No improvement in eval loss for {no_improvement_evals} evaluations\")\n",
        "                        if no_improvement_evals >= max_no_improvement_evals:\n",
        "                            print(f\"No improvement in eval loss for {no_improvement_evals} evaluations and max no improvement evals is {max_no_improvement_evals}, so stopping\")\n",
        "                            time_to_stop = True\n",
        "\n",
        "                    if time_to_stop:\n",
        "                        break\n",
        "\n",
        "                    model.train()\n",
        "\n",
        "                if curr_step % 10 == 0:\n",
        "                    print(f\"Loss at step {curr_step} is {loss.item():.4f}\")\n",
        "                    wandb.log({\n",
        "                        \"Train Loss\": loss.item(),\n",
        "                        \"Step\": curr_step\n",
        "                    })\n",
        "\n",
        "                progress.update(1)\n",
        "\n",
        "            avg_loss = total_loss / len(dataloader_train)\n",
        "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "            wandb.log({\n",
        "                \"Epoch Loss\": avg_loss,\n",
        "                \"Epoch\": epoch + 1\n",
        "            })\n",
        "\n",
        "            if time_to_stop:\n",
        "                break\n",
        "\n",
        "        if not time_to_stop:  # Eval on the final checkpoint to see if it's any better or not.\n",
        "            print(\"Model has not converged till the last batch so doing a final evaluation.\")\n",
        "\n",
        "            final_loss, final_correlation = evaluate(model, encoder, dataloader_val, criterion)\n",
        "\n",
        "            print(f\"Eval loss after {curr_step} steps is {final_loss:.4f}\")\n",
        "            print(f\"Final Correlation after {curr_step} steps is {final_correlation:.4f}\")\n",
        "\n",
        "            # Log to wandb\n",
        "            wandb.log({\n",
        "                \"Final Eval Loss\": final_loss,\n",
        "                \"Final Pearson Correlation\": final_correlation\n",
        "            })\n",
        "\n",
        "            if final_loss < previous_eval_loss:\n",
        "                print(\"Saving final model since validation loss reduced\")\n",
        "                model.save_pretrained(save_path)\n",
        "                encoder.save_pretrained(save_path)\n",
        "            else:\n",
        "                print(\"No improvement in eval loss even after the final batch.\")\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        print(\"Evaluating on the test set.\")\n",
        "        test_loss, test_correlation = evaluate(model, encoder, dataloader_test, criterion)\n",
        "        print(f\"Test loss: {test_loss:.4f}\")\n",
        "        print(f\"Test Pearson Correlation: {test_correlation:.4f}\")\n",
        "\n",
        "        wandb.log({\n",
        "            \"Test Loss\": test_loss,\n",
        "            \"Test Pearson Correlation\": test_correlation\n",
        "        })\n",
        "\n",
        "# Usage\n",
        "# train(model, encoder, dataloader_train, dataloader_val, dataloader_test, optimizer, scheduler, criterion, epochs=5, eval_every_n_steps=50, max_no_improvement_evals=3, save_path='model_save_path')\n"
      ],
      "metadata": {
        "id": "UbxA19_vqKPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lOhwi52lKQ6w"
      },
      "outputs": [],
      "source": [
        "#Model Parameters\n",
        "model_name = 'ai4bharat/IndicBERTv2-MLM-only'\n",
        "dataset_train_path = '/content/new_train_da.csv'\n",
        "dataset_val_path = '/content/new_val_da.csv'\n",
        "\n",
        "attention_dropout = 0.1\n",
        "hidden_dropout = 0.1\n",
        "activation_dropout = 0.1\n",
        "train_batch_size=8\n",
        "val_batch_size=8\n",
        "max_length=50\n",
        "pooling_logic=\"layerwise_attention_mean\"\n",
        "\n",
        "r = 1\n",
        "lora_alpha = 2\n",
        "target_modules = [\"attention.self.query\", \"attention.self.value\", \"attention.self.key\", \"attention.output.dense\", \"mlp.dense_h_to_4h\", \"mlp.dense_4h_to_h\"]\n",
        "\n",
        "lora_dropout = 0.05\n",
        "lr = 3e-6\n",
        "epochs = 2\n",
        "gradient_accumulation_steps = 1\n",
        "use_8bit_adam = False\n",
        "criterion = nn.MSELoss()\n",
        "eval_every_n_steps = 50\n",
        "max_no_improvement_evals = 3\n",
        "save_path = './checkpoints/'\n",
        "is_deepspeed = False\n",
        "lora = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8hs9oHnGIwl",
        "outputId": "ba4b0a78-064a-4048-9344-1daf2f8c0904"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maaryapakhale01\u001b[0m (\u001b[33mindian-insititute-of-technology-kharagpur\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "toKR3SgXi85u",
        "outputId": "112b3f4e-105f-465c-c195-b5782936f1c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maaryapakhale01\u001b[0m (\u001b[33mindian-insititute-of-technology-kharagpur\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240803_131339-yio3ghku</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/indian-insititute-of-technology-kharagpur/New%20Indicrun/runs/yio3ghku' target=\"_blank\">classic-jazz-4</a></strong> to <a href='https://wandb.ai/indian-insititute-of-technology-kharagpur/New%20Indicrun' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/indian-insititute-of-technology-kharagpur/New%20Indicrun' target=\"_blank\">https://wandb.ai/indian-insititute-of-technology-kharagpur/New%20Indicrun</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/indian-insititute-of-technology-kharagpur/New%20Indicrun/runs/yio3ghku' target=\"_blank\">https://wandb.ai/indian-insititute-of-technology-kharagpur/New%20Indicrun/runs/yio3ghku</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datasets...\n",
            "Loading encoder and tokenizer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ai4bharat/IndicBERTv2-MLM-only were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing datasets and merging them...\n",
            "Creating dataloaders...\n",
            "Loading model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting optimizer and scheduler...\n",
            "Total number of training steps is: 3125 and warmup steps is: 312\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3125 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 out of 5 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 10/3125 [03:05<15:14:22, 17.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 10 is 0.6351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 20/3125 [06:00<14:53:52, 17.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 20 is 0.8094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 30/3125 [09:09<16:21:44, 19.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 30 is 0.8669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 40/3125 [12:05<15:12:37, 17.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 40 is 0.5554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 49/3125 [14:43<14:54:59, 17.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:04<08:53,  4.30s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:07<07:50,  3.83s/it]\u001b[A\n",
            "  2%|▏         | 3/125 [00:11<07:29,  3.69s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:16<08:24,  4.17s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:19<07:49,  3.91s/it]\u001b[A\n",
            "  5%|▍         | 6/125 [00:23<07:25,  3.74s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:26<07:22,  3.75s/it]\u001b[A\n",
            "  6%|▋         | 8/125 [00:31<07:53,  4.04s/it]\u001b[A\n",
            "  7%|▋         | 9/125 [00:34<07:26,  3.85s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:38<07:10,  3.75s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:43<07:38,  4.02s/it]\u001b[A\n",
            " 10%|▉         | 12/125 [00:46<07:26,  3.95s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:50<07:06,  3.81s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:54<07:05,  3.84s/it]\u001b[A\n",
            " 12%|█▏        | 15/125 [01:00<08:21,  4.56s/it]\u001b[A\n",
            " 13%|█▎        | 16/125 [01:04<07:55,  4.36s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [01:07<07:24,  4.12s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [01:12<07:33,  4.24s/it]\u001b[A\n",
            " 15%|█▌        | 19/125 [01:16<07:23,  4.19s/it]\u001b[A\n",
            " 16%|█▌        | 20/125 [01:20<06:58,  3.99s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [01:23<06:43,  3.88s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [01:28<07:13,  4.21s/it]\u001b[A\n",
            " 18%|█▊        | 23/125 [01:32<06:48,  4.01s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [01:35<06:29,  3.85s/it]\u001b[A\n",
            " 20%|██        | 25/125 [01:40<06:43,  4.04s/it]\u001b[A\n",
            " 21%|██        | 26/125 [01:44<06:40,  4.05s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [01:47<06:23,  3.91s/it]\u001b[A\n",
            " 22%|██▏       | 28/125 [01:51<06:08,  3.79s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [01:56<06:39,  4.16s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [02:00<06:20,  4.01s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [02:03<06:06,  3.89s/it]\u001b[A\n",
            " 26%|██▌       | 32/125 [02:08<06:18,  4.07s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [02:12<06:11,  4.04s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [02:15<05:55,  3.90s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [02:19<05:39,  3.77s/it]\u001b[A\n",
            " 29%|██▉       | 36/125 [02:24<06:07,  4.13s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [02:27<05:49,  3.97s/it]\u001b[A\n",
            " 30%|███       | 38/125 [02:31<05:35,  3.86s/it]\u001b[A\n",
            " 31%|███       | 39/125 [02:35<05:48,  4.05s/it]\u001b[A\n",
            " 32%|███▏      | 40/125 [02:39<05:46,  4.08s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [02:43<05:30,  3.93s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [02:47<05:17,  3.83s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [02:52<05:41,  4.16s/it]\u001b[A\n",
            " 35%|███▌      | 44/125 [02:55<05:23,  4.00s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [02:59<05:12,  3.90s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [03:03<05:21,  4.07s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [03:07<05:18,  4.09s/it]\u001b[A\n",
            " 38%|███▊      | 48/125 [03:11<05:02,  3.93s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [03:15<04:50,  3.82s/it]\u001b[A\n",
            " 40%|████      | 50/125 [03:20<05:29,  4.39s/it]\u001b[A\n",
            " 41%|████      | 51/125 [03:25<05:24,  4.39s/it]\u001b[A\n",
            " 42%|████▏     | 52/125 [03:28<05:01,  4.13s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [03:33<05:12,  4.34s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [03:37<04:51,  4.11s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [03:40<04:35,  3.93s/it]\u001b[A\n",
            " 45%|████▍     | 56/125 [03:44<04:28,  3.89s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [03:49<04:41,  4.15s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [03:52<04:25,  3.96s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [03:56<04:13,  3.84s/it]\u001b[A\n",
            " 48%|████▊     | 60/125 [04:01<04:28,  4.13s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [04:04<04:17,  4.03s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [04:08<04:08,  3.95s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [04:12<04:05,  3.96s/it]\u001b[A\n",
            " 51%|█████     | 64/125 [04:17<04:12,  4.13s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [04:20<03:57,  3.96s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [04:24<03:47,  3.86s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [04:29<04:03,  4.21s/it]\u001b[A\n",
            " 54%|█████▍    | 68/125 [04:32<03:48,  4.01s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [04:36<03:36,  3.86s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [04:40<03:32,  3.86s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [04:44<03:39,  4.07s/it]\u001b[A\n",
            " 58%|█████▊    | 72/125 [04:48<03:26,  3.90s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [04:51<03:16,  3.77s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [04:56<03:29,  4.12s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [05:00<03:17,  3.96s/it]\u001b[A\n",
            " 61%|██████    | 76/125 [05:03<03:07,  3.82s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [05:07<03:00,  3.77s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [05:12<03:12,  4.09s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [05:15<03:01,  3.94s/it]\u001b[A\n",
            " 64%|██████▍   | 80/125 [05:19<02:52,  3.83s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [05:24<02:59,  4.07s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [05:27<02:51,  3.99s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [05:31<02:42,  3.86s/it]\u001b[A\n",
            " 67%|██████▋   | 84/125 [05:35<02:35,  3.78s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [05:39<02:44,  4.10s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [05:44<02:43,  4.19s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [05:48<02:38,  4.18s/it]\u001b[A\n",
            " 70%|███████   | 88/125 [05:53<02:43,  4.42s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [05:56<02:29,  4.16s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [06:00<02:18,  3.96s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [06:04<02:18,  4.08s/it]\u001b[A\n",
            " 74%|███████▎  | 92/125 [06:08<02:14,  4.09s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [06:12<02:04,  3.88s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [06:16<01:58,  3.83s/it]\u001b[A\n",
            " 76%|███████▌  | 95/125 [06:21<02:05,  4.19s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [06:24<01:56,  4.01s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [06:28<01:48,  3.87s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [06:32<01:49,  4.06s/it]\u001b[A\n",
            " 79%|███████▉  | 99/125 [06:36<01:46,  4.08s/it]\u001b[A\n",
            " 80%|████████  | 100/125 [06:40<01:37,  3.92s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [06:43<01:31,  3.81s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [06:48<01:35,  4.16s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [06:52<01:25,  3.90s/it]\u001b[A\n",
            " 83%|████████▎ | 104/125 [06:55<01:19,  3.79s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [06:59<01:18,  3.91s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [07:04<01:16,  4.02s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [07:07<01:09,  3.88s/it]\u001b[A\n",
            " 86%|████████▋ | 108/125 [07:11<01:04,  3.77s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [07:16<01:05,  4.11s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [07:19<00:59,  3.96s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [07:23<00:53,  3.82s/it]\u001b[A\n",
            " 90%|████████▉ | 112/125 [07:27<00:50,  3.90s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [07:31<00:47,  3.99s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [07:35<00:42,  3.85s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [07:38<00:37,  3.74s/it]\u001b[A\n",
            " 93%|█████████▎| 116/125 [07:43<00:36,  4.10s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [07:47<00:31,  3.94s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [07:50<00:26,  3.80s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [07:54<00:23,  3.91s/it]\u001b[A\n",
            " 96%|█████████▌| 120/125 [07:59<00:20,  4.06s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [08:02<00:15,  3.89s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [08:06<00:11,  3.82s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [08:12<00:09,  4.52s/it]\u001b[A\n",
            " 99%|█████████▉| 124/125 [08:16<00:04,  4.25s/it]\u001b[A\n",
            "100%|██████████| 125/125 [08:19<00:00,  4.00s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss after 50 steps is 0.6107\n",
            "Final Correlation after 50 steps is 0.0339\n",
            "Saving model since validation loss reduced\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'suppress_tokens': []}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "  2%|▏         | 50/3125 [24:36<162:23:51, 190.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 50 is 0.7056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 60/3125 [27:37<19:13:45, 22.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 60 is 0.5828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 70/3125 [30:38<15:39:57, 18.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 70 is 0.7117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 80/3125 [33:37<15:07:11, 17.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 80 is 0.3791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 90/3125 [36:38<14:57:49, 17.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 90 is 0.4436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 99/3125 [39:18<14:42:31, 17.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:03<07:13,  3.49s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:06<07:07,  3.47s/it]\u001b[A\n",
            "  2%|▏         | 3/125 [00:11<08:02,  3.95s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:15<07:56,  3.94s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:18<07:34,  3.78s/it]\u001b[A\n",
            "  5%|▍         | 6/125 [00:22<07:30,  3.79s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:27<08:08,  4.14s/it]\u001b[A\n",
            "  6%|▋         | 8/125 [00:31<07:56,  4.07s/it]\u001b[A\n",
            "  7%|▋         | 9/125 [00:35<07:34,  3.92s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:40<08:12,  4.28s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:43<07:41,  4.05s/it]\u001b[A\n",
            " 10%|▉         | 12/125 [00:47<07:32,  4.00s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:53<08:22,  4.49s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:57<07:57,  4.31s/it]\u001b[A\n",
            " 12%|█▏        | 15/125 [01:00<07:26,  4.06s/it]\u001b[A\n",
            " 13%|█▎        | 16/125 [01:03<07:01,  3.86s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [01:08<07:33,  4.20s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [01:12<07:07,  4.00s/it]\u001b[A\n",
            " 15%|█▌        | 19/125 [01:16<06:49,  3.86s/it]\u001b[A\n",
            " 16%|█▌        | 20/125 [01:20<06:59,  4.00s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [01:24<07:01,  4.05s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [01:28<06:40,  3.89s/it]\u001b[A\n",
            " 18%|█▊        | 23/125 [01:31<06:22,  3.75s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [01:36<06:53,  4.09s/it]\u001b[A\n",
            " 20%|██        | 25/125 [01:39<06:31,  3.92s/it]\u001b[A\n",
            " 21%|██        | 26/125 [01:43<06:17,  3.81s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [01:47<06:24,  3.92s/it]\u001b[A\n",
            " 22%|██▏       | 28/125 [01:51<06:33,  4.06s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [01:55<06:15,  3.91s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [01:59<05:59,  3.78s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [02:04<06:31,  4.16s/it]\u001b[A\n",
            " 26%|██▌       | 32/125 [02:07<06:13,  4.01s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [02:11<05:56,  3.88s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [02:15<06:00,  3.96s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [02:19<06:08,  4.09s/it]\u001b[A\n",
            " 29%|██▉       | 36/125 [02:23<05:51,  3.95s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [02:26<05:36,  3.82s/it]\u001b[A\n",
            " 30%|███       | 38/125 [02:31<06:02,  4.17s/it]\u001b[A\n",
            " 31%|███       | 39/125 [02:35<05:43,  3.99s/it]\u001b[A\n",
            " 32%|███▏      | 40/125 [02:39<05:28,  3.87s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [02:43<05:35,  4.00s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [02:47<05:41,  4.12s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [02:51<05:22,  3.94s/it]\u001b[A\n",
            " 35%|███▌      | 44/125 [02:54<05:10,  3.83s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [02:59<05:34,  4.18s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [03:03<05:18,  4.04s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [03:07<05:03,  3.89s/it]\u001b[A\n",
            " 38%|███▊      | 48/125 [03:11<05:07,  3.99s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [03:15<05:13,  4.12s/it]\u001b[A\n",
            " 40%|████      | 50/125 [03:19<04:57,  3.96s/it]\u001b[A\n",
            " 41%|████      | 51/125 [03:23<04:46,  3.88s/it]\u001b[A\n",
            " 42%|████▏     | 52/125 [03:29<05:27,  4.49s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [03:33<05:20,  4.46s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [03:36<04:57,  4.19s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [03:41<04:51,  4.17s/it]\u001b[A\n",
            " 45%|████▍     | 56/125 [03:45<04:52,  4.24s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [03:49<04:37,  4.07s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [03:52<04:24,  3.94s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [03:57<04:42,  4.28s/it]\u001b[A\n",
            " 48%|████▊     | 60/125 [04:01<04:25,  4.08s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [04:05<04:11,  3.93s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [04:09<04:15,  4.06s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [04:13<04:15,  4.11s/it]\u001b[A\n",
            " 51%|█████     | 64/125 [04:17<04:02,  3.97s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [04:20<03:52,  3.87s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [04:25<04:07,  4.20s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [04:29<03:51,  3.98s/it]\u001b[A\n",
            " 54%|█████▍    | 68/125 [04:32<03:39,  3.86s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [04:37<03:42,  3.98s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [04:45<04:50,  5.28s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [04:49<04:22,  4.87s/it]\u001b[A\n",
            " 58%|█████▊    | 72/125 [04:54<04:13,  4.79s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [04:58<03:59,  4.60s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [05:01<03:38,  4.29s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [05:05<03:24,  4.09s/it]\u001b[A\n",
            " 61%|██████    | 76/125 [05:10<03:34,  4.37s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [05:14<03:18,  4.14s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [05:17<03:07,  3.99s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [05:22<03:11,  4.17s/it]\u001b[A\n",
            " 64%|██████▍   | 80/125 [05:26<03:05,  4.11s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [05:29<02:53,  3.94s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [05:33<02:45,  3.84s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [05:38<02:55,  4.18s/it]\u001b[A\n",
            " 67%|██████▋   | 84/125 [05:41<02:43,  3.99s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [05:45<02:33,  3.85s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [05:49<02:37,  4.04s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [05:53<02:33,  4.04s/it]\u001b[A\n",
            " 70%|███████   | 88/125 [05:58<02:34,  4.17s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [06:03<02:36,  4.35s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [06:07<02:31,  4.33s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [06:11<02:19,  4.11s/it]\u001b[A\n",
            " 74%|███████▎  | 92/125 [06:14<02:09,  3.93s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [06:19<02:16,  4.26s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [06:23<02:07,  4.10s/it]\u001b[A\n",
            " 76%|███████▌  | 95/125 [06:26<01:57,  3.92s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [06:31<01:56,  4.02s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [06:35<01:54,  4.10s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [06:38<01:46,  3.94s/it]\u001b[A\n",
            " 79%|███████▉  | 99/125 [06:42<01:39,  3.83s/it]\u001b[A\n",
            " 80%|████████  | 100/125 [06:47<01:45,  4.21s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [06:51<01:36,  4.01s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [06:54<01:30,  3.92s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [06:59<01:31,  4.15s/it]\u001b[A\n",
            " 83%|████████▎ | 104/125 [07:03<01:26,  4.14s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [07:07<01:19,  3.98s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [07:10<01:13,  3.86s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [07:15<01:15,  4.22s/it]\u001b[A\n",
            " 86%|████████▋ | 108/125 [07:19<01:08,  4.05s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [07:23<01:03,  3.94s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [07:27<01:02,  4.15s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [07:31<00:57,  4.09s/it]\u001b[A\n",
            " 90%|████████▉ | 112/125 [07:35<00:50,  3.92s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [07:38<00:45,  3.82s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [07:43<00:45,  4.18s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [07:47<00:40,  4.02s/it]\u001b[A\n",
            " 93%|█████████▎| 116/125 [07:51<00:34,  3.88s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [07:55<00:32,  4.11s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [07:59<00:28,  4.03s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [08:03<00:23,  3.88s/it]\u001b[A\n",
            " 96%|█████████▌| 120/125 [08:06<00:18,  3.76s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [08:11<00:16,  4.12s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [08:15<00:11,  3.95s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [08:18<00:07,  3.84s/it]\u001b[A\n",
            " 99%|█████████▉| 124/125 [08:23<00:04,  4.08s/it]\u001b[A\n",
            "100%|██████████| 125/125 [08:27<00:00,  4.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss after 100 steps is 0.4884\n",
            "Final Correlation after 100 steps is 0.0148\n",
            "Saving model since validation loss reduced\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'suppress_tokens': []}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "  3%|▎         | 100/3125 [48:44<152:59:07, 182.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 100 is 0.4400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▎         | 110/3125 [51:45<18:52:20, 22.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 110 is 0.5470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 120/3125 [54:47<15:52:43, 19.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 120 is 0.2674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 130/3125 [57:45<14:39:43, 17.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 130 is 0.3226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 140/3125 [1:00:47<16:07:18, 19.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 140 is 0.3095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 149/3125 [1:03:31<14:51:38, 17.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:03<07:36,  3.68s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:07<07:36,  3.71s/it]\u001b[A\n",
            "  2%|▏         | 3/125 [00:11<07:48,  3.84s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:16<08:41,  4.31s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:20<08:06,  4.06s/it]\u001b[A\n",
            "  5%|▍         | 6/125 [00:23<07:40,  3.87s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:28<08:20,  4.24s/it]\u001b[A\n",
            "  6%|▋         | 8/125 [00:32<07:51,  4.03s/it]\u001b[A\n",
            "  7%|▋         | 9/125 [00:35<07:30,  3.89s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:39<07:38,  3.98s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:44<07:49,  4.12s/it]\u001b[A\n",
            " 10%|▉         | 12/125 [00:47<07:26,  3.95s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:51<07:09,  3.83s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:59<09:21,  5.06s/it]\u001b[A\n",
            " 12%|█▏        | 15/125 [01:02<08:26,  4.60s/it]\u001b[A\n",
            " 13%|█▎        | 16/125 [01:06<07:48,  4.30s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [01:10<07:37,  4.23s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [01:14<07:37,  4.27s/it]\u001b[A\n",
            " 15%|█▌        | 19/125 [01:18<07:09,  4.05s/it]\u001b[A\n",
            " 16%|█▌        | 20/125 [01:21<06:48,  3.89s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [01:26<07:13,  4.16s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [01:30<06:48,  3.97s/it]\u001b[A\n",
            " 18%|█▊        | 23/125 [01:33<06:31,  3.84s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [01:37<06:29,  3.86s/it]\u001b[A\n",
            " 20%|██        | 25/125 [01:42<06:45,  4.05s/it]\u001b[A\n",
            " 21%|██        | 26/125 [01:45<06:24,  3.89s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [01:49<06:08,  3.76s/it]\u001b[A\n",
            " 22%|██▏       | 28/125 [01:54<06:38,  4.11s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [01:57<06:15,  3.92s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [02:01<06:00,  3.80s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [02:04<05:58,  3.82s/it]\u001b[A\n",
            " 26%|██▌       | 32/125 [02:09<06:16,  4.05s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [02:13<05:58,  3.89s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [02:17<06:10,  4.07s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [02:23<06:43,  4.48s/it]\u001b[A\n",
            " 29%|██▉       | 36/125 [02:26<06:12,  4.19s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [02:30<05:49,  3.98s/it]\u001b[A\n",
            " 30%|███       | 38/125 [02:34<05:50,  4.03s/it]\u001b[A\n",
            " 31%|███       | 39/125 [02:38<05:53,  4.11s/it]\u001b[A\n",
            " 32%|███▏      | 40/125 [02:41<05:34,  3.93s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [02:45<05:19,  3.81s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [02:50<05:43,  4.14s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [02:53<05:23,  3.95s/it]\u001b[A\n",
            " 35%|███▌      | 44/125 [02:57<05:08,  3.81s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [03:01<05:10,  3.88s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [03:05<05:18,  4.03s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [03:09<05:03,  3.89s/it]\u001b[A\n",
            " 38%|███▊      | 48/125 [03:12<04:51,  3.78s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [03:17<05:13,  4.12s/it]\u001b[A\n",
            " 40%|████      | 50/125 [03:21<04:55,  3.94s/it]\u001b[A\n",
            " 41%|████      | 51/125 [03:24<04:42,  3.81s/it]\u001b[A\n",
            " 42%|████▏     | 52/125 [03:28<04:39,  3.83s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [03:33<04:51,  4.05s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [03:36<04:36,  3.90s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [03:40<04:25,  3.79s/it]\u001b[A\n",
            " 45%|████▍     | 56/125 [03:45<04:56,  4.29s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [03:50<05:00,  4.42s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [03:54<04:37,  4.15s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [03:57<04:21,  3.96s/it]\u001b[A\n",
            " 48%|████▊     | 60/125 [04:02<04:35,  4.24s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [04:06<04:18,  4.04s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [04:09<04:04,  3.89s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [04:13<04:04,  3.94s/it]\u001b[A\n",
            " 51%|█████     | 64/125 [04:18<04:08,  4.08s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [04:21<03:54,  3.91s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [04:25<03:42,  3.77s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [04:29<03:57,  4.09s/it]\u001b[A\n",
            " 54%|█████▍    | 68/125 [04:33<03:45,  3.95s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [04:37<03:34,  3.83s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [04:40<03:31,  3.84s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [04:45<03:39,  4.07s/it]\u001b[A\n",
            " 58%|█████▊    | 72/125 [04:49<03:26,  3.90s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [04:54<03:40,  4.24s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [04:58<03:46,  4.44s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [05:02<03:27,  4.16s/it]\u001b[A\n",
            " 61%|██████    | 76/125 [05:05<03:14,  3.98s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [05:10<03:18,  4.14s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [05:14<03:11,  4.07s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [05:17<03:00,  3.92s/it]\u001b[A\n",
            " 64%|██████▍   | 80/125 [05:21<02:51,  3.80s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [05:26<03:02,  4.14s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [05:29<02:49,  3.95s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [05:33<02:40,  3.82s/it]\u001b[A\n",
            " 67%|██████▋   | 84/125 [05:37<02:45,  4.03s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [05:42<02:40,  4.02s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [05:45<02:30,  3.85s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [05:48<02:21,  3.73s/it]\u001b[A\n",
            " 70%|███████   | 88/125 [05:54<02:33,  4.16s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [05:57<02:23,  3.98s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [06:01<02:14,  3.86s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [06:06<02:22,  4.19s/it]\u001b[A\n",
            " 74%|███████▎  | 92/125 [06:10<02:16,  4.14s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [06:13<02:06,  3.97s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [06:17<01:59,  3.87s/it]\u001b[A\n",
            " 76%|███████▌  | 95/125 [06:22<02:05,  4.19s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [06:25<01:55,  3.99s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [06:29<01:48,  3.87s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [06:34<01:51,  4.12s/it]\u001b[A\n",
            " 79%|███████▉  | 99/125 [06:37<01:44,  4.03s/it]\u001b[A\n",
            " 80%|████████  | 100/125 [06:41<01:36,  3.87s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [06:45<01:31,  3.81s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [06:50<01:35,  4.13s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [06:53<01:27,  3.98s/it]\u001b[A\n",
            " 83%|████████▎ | 104/125 [06:57<01:20,  3.85s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [07:01<01:21,  4.08s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [07:05<01:16,  4.03s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [07:09<01:10,  3.90s/it]\u001b[A\n",
            " 86%|████████▋ | 108/125 [07:12<01:04,  3.82s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [07:17<01:05,  4.11s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [07:21<00:59,  3.95s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [07:24<00:53,  3.82s/it]\u001b[A\n",
            " 90%|████████▉ | 112/125 [07:29<00:54,  4.21s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [07:35<00:53,  4.50s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [07:38<00:46,  4.23s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [07:42<00:40,  4.02s/it]\u001b[A\n",
            " 93%|█████████▎| 116/125 [07:46<00:38,  4.23s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [07:50<00:32,  4.08s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [07:54<00:27,  3.92s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [07:58<00:23,  3.88s/it]\u001b[A\n",
            " 96%|█████████▌| 120/125 [08:02<00:20,  4.18s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [08:06<00:16,  4.01s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [08:10<00:11,  3.88s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [08:14<00:08,  4.16s/it]\u001b[A\n",
            " 99%|█████████▉| 124/125 [08:19<00:04,  4.32s/it]\u001b[A\n",
            "100%|██████████| 125/125 [08:23<00:00,  4.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss after 150 steps is 0.2559\n",
            "Final Correlation after 150 steps is 0.0206\n",
            "Saving model since validation loss reduced\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'suppress_tokens': []}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "  5%|▍         | 150/3125 [1:12:54<150:07:39, 181.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 150 is 1.5249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 160/3125 [1:15:58<18:51:25, 22.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 160 is 0.1794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 170/3125 [1:18:57<15:02:50, 18.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 170 is 0.0819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 180/3125 [1:21:55<14:34:37, 17.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 180 is 0.1090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 190/3125 [1:24:50<14:24:58, 17.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 190 is 0.1074\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▋         | 199/3125 [1:27:39<14:57:45, 18.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:04<08:28,  4.10s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:08<08:44,  4.26s/it]\u001b[A\n",
            "  2%|▏         | 3/125 [00:12<07:59,  3.93s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:15<07:33,  3.74s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:20<08:17,  4.15s/it]\u001b[A\n",
            "  5%|▍         | 6/125 [00:23<07:46,  3.92s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:27<07:26,  3.78s/it]\u001b[A\n",
            "  6%|▋         | 8/125 [00:31<07:19,  3.76s/it]\u001b[A\n",
            "  7%|▋         | 9/125 [00:35<07:48,  4.04s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:39<07:25,  3.87s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:42<07:09,  3.77s/it]\u001b[A\n",
            " 10%|▉         | 12/125 [00:47<07:36,  4.04s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:51<07:23,  3.96s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:54<07:03,  3.81s/it]\u001b[A\n",
            " 12%|█▏        | 15/125 [00:58<06:51,  3.74s/it]\u001b[A\n",
            " 13%|█▎        | 16/125 [01:03<07:24,  4.08s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [01:06<07:00,  3.90s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [01:10<06:43,  3.78s/it]\u001b[A\n",
            " 15%|█▌        | 19/125 [01:14<07:00,  3.96s/it]\u001b[A\n",
            " 16%|█▌        | 20/125 [01:18<06:55,  3.96s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [01:21<06:36,  3.81s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [01:25<06:22,  3.71s/it]\u001b[A\n",
            " 18%|█▊        | 23/125 [01:30<06:54,  4.07s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [01:33<06:31,  3.88s/it]\u001b[A\n",
            " 20%|██        | 25/125 [01:37<06:14,  3.75s/it]\u001b[A\n",
            " 21%|██        | 26/125 [01:41<06:22,  3.86s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [01:45<06:35,  4.04s/it]\u001b[A\n",
            " 22%|██▏       | 28/125 [01:50<06:52,  4.25s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [01:54<06:35,  4.12s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [01:58<06:44,  4.26s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [02:02<06:19,  4.04s/it]\u001b[A\n",
            " 26%|██▌       | 32/125 [02:05<05:59,  3.87s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [02:10<06:22,  4.16s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [02:14<06:03,  4.00s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [02:17<05:47,  3.86s/it]\u001b[A\n",
            " 29%|██▉       | 36/125 [02:21<05:37,  3.79s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [02:26<06:00,  4.09s/it]\u001b[A\n",
            " 30%|███       | 38/125 [02:29<05:41,  3.92s/it]\u001b[A\n",
            " 31%|███       | 39/125 [02:33<05:26,  3.80s/it]\u001b[A\n",
            " 32%|███▏      | 40/125 [02:37<05:40,  4.00s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [02:41<05:35,  3.99s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [02:45<05:19,  3.86s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [02:48<05:05,  3.72s/it]\u001b[A\n",
            " 35%|███▌      | 44/125 [02:53<05:32,  4.10s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [02:57<05:19,  3.99s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [03:00<05:04,  3.86s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [03:05<05:16,  4.06s/it]\u001b[A\n",
            " 38%|███▊      | 48/125 [03:09<05:04,  3.96s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [03:12<04:50,  3.83s/it]\u001b[A\n",
            " 40%|████      | 50/125 [03:16<04:39,  3.73s/it]\u001b[A\n",
            " 41%|████      | 51/125 [03:20<04:58,  4.03s/it]\u001b[A\n",
            " 42%|████▏     | 52/125 [03:24<04:42,  3.88s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [03:27<04:30,  3.76s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [03:32<04:44,  4.00s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [03:36<04:35,  3.93s/it]\u001b[A\n",
            " 45%|████▍     | 56/125 [03:39<04:24,  3.83s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [03:43<04:16,  3.77s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [03:48<04:30,  4.04s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [03:51<04:15,  3.87s/it]\u001b[A\n",
            " 48%|████▊     | 60/125 [03:55<04:04,  3.76s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [03:59<04:18,  4.05s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [04:03<04:05,  3.90s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [04:06<03:54,  3.79s/it]\u001b[A\n",
            " 51%|█████     | 64/125 [04:10<03:51,  3.80s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [04:15<04:02,  4.05s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [04:19<04:07,  4.19s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [04:25<04:22,  4.53s/it]\u001b[A\n",
            " 54%|█████▍    | 68/125 [04:31<04:45,  5.01s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [04:34<04:15,  4.56s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [04:38<03:52,  4.24s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [04:42<03:47,  4.22s/it]\u001b[A\n",
            " 58%|█████▊    | 72/125 [04:46<03:43,  4.22s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [04:50<03:28,  4.01s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [04:53<03:16,  3.86s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [04:58<03:29,  4.20s/it]\u001b[A\n",
            " 61%|██████    | 76/125 [05:02<03:17,  4.04s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [05:06<03:07,  3.91s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [05:10<03:09,  4.02s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [05:14<03:07,  4.09s/it]\u001b[A\n",
            " 64%|██████▍   | 80/125 [05:18<02:55,  3.90s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [05:21<02:46,  3.79s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [05:26<03:01,  4.23s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [05:30<02:48,  4.02s/it]\u001b[A\n",
            " 67%|██████▋   | 84/125 [05:33<02:39,  3.88s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [05:38<02:40,  4.01s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [05:42<02:38,  4.07s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [05:46<02:28,  3.92s/it]\u001b[A\n",
            " 70%|███████   | 88/125 [05:49<02:20,  3.80s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [05:54<02:28,  4.14s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [05:57<02:18,  3.95s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [06:01<02:10,  3.83s/it]\u001b[A\n",
            " 74%|███████▎  | 92/125 [06:05<02:09,  3.94s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [06:09<02:08,  4.02s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [06:13<02:00,  3.87s/it]\u001b[A\n",
            " 76%|███████▌  | 95/125 [06:17<01:53,  3.78s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [06:21<01:59,  4.13s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [06:25<01:50,  3.93s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [06:28<01:42,  3.80s/it]\u001b[A\n",
            " 79%|███████▉  | 99/125 [06:32<01:40,  3.85s/it]\u001b[A\n",
            " 80%|████████  | 100/125 [06:37<01:39,  3.97s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [06:40<01:32,  3.84s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [06:44<01:26,  3.75s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [06:49<01:29,  4.07s/it]\u001b[A\n",
            " 83%|████████▎ | 104/125 [06:52<01:21,  3.89s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [06:56<01:15,  3.77s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [07:00<01:13,  3.85s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [07:04<01:13,  4.08s/it]\u001b[A\n",
            " 86%|████████▋ | 108/125 [07:09<01:13,  4.29s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [07:13<01:06,  4.13s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [07:17<01:04,  4.28s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [07:21<00:56,  4.03s/it]\u001b[A\n",
            " 90%|████████▉ | 112/125 [07:24<00:50,  3.88s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [07:29<00:49,  4.14s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [07:33<00:44,  4.03s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [07:36<00:39,  3.91s/it]\u001b[A\n",
            " 93%|█████████▎| 116/125 [07:40<00:34,  3.86s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [07:45<00:33,  4.15s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [07:49<00:27,  3.97s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [07:52<00:23,  3.84s/it]\u001b[A\n",
            " 96%|█████████▌| 120/125 [07:57<00:20,  4.09s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [08:01<00:16,  4.01s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [08:04<00:11,  3.88s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [08:08<00:07,  3.85s/it]\u001b[A\n",
            " 99%|█████████▉| 124/125 [08:13<00:04,  4.16s/it]\u001b[A\n",
            "100%|██████████| 125/125 [08:17<00:00,  3.98s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss after 200 steps is 0.0845\n",
            "Final Correlation after 200 steps is 0.0124\n",
            "Saving model since validation loss reduced\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'suppress_tokens': []}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "  6%|▋         | 200/3125 [1:37:04<148:11:15, 182.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 200 is 0.0192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 210/3125 [1:40:10<17:59:55, 22.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 210 is 0.1003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 220/3125 [1:43:10<14:31:16, 18.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 220 is 0.0298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 230/3125 [1:46:08<14:32:16, 18.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 230 is 0.0740\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 240/3125 [1:49:10<14:15:43, 17.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 240 is 0.0421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 249/3125 [1:51:51<14:18:13, 17.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:03<07:09,  3.46s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:08<08:39,  4.22s/it]\u001b[A\n",
            "  2%|▏         | 3/125 [00:11<08:03,  3.96s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:15<07:36,  3.77s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:18<07:23,  3.69s/it]\u001b[A\n",
            "  5%|▍         | 6/125 [00:23<08:04,  4.08s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:27<07:38,  3.89s/it]\u001b[A\n",
            "  6%|▋         | 8/125 [00:30<07:18,  3.75s/it]\u001b[A\n",
            "  7%|▋         | 9/125 [00:35<07:38,  3.95s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:38<07:33,  3.94s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:42<07:13,  3.80s/it]\u001b[A\n",
            " 10%|▉         | 12/125 [00:45<06:58,  3.71s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:50<07:32,  4.04s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:54<07:10,  3.88s/it]\u001b[A\n",
            " 12%|█▏        | 15/125 [00:57<06:53,  3.76s/it]\u001b[A\n",
            " 13%|█▎        | 16/125 [01:02<07:10,  3.95s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [01:06<07:09,  3.98s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [01:09<06:50,  3.84s/it]\u001b[A\n",
            " 15%|█▌        | 19/125 [01:13<06:34,  3.72s/it]\u001b[A\n",
            " 16%|█▌        | 20/125 [01:18<07:09,  4.09s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [01:21<06:47,  3.92s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [01:25<06:30,  3.79s/it]\u001b[A\n",
            " 18%|█▊        | 23/125 [01:29<06:36,  3.89s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [01:33<06:46,  4.02s/it]\u001b[A\n",
            " 20%|██        | 25/125 [01:37<06:26,  3.87s/it]\u001b[A\n",
            " 21%|██        | 26/125 [01:40<06:08,  3.72s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [01:45<06:42,  4.11s/it]\u001b[A\n",
            " 22%|██▏       | 28/125 [01:50<07:01,  4.35s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [01:53<06:34,  4.11s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [01:57<06:23,  4.04s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [02:02<06:32,  4.17s/it]\u001b[A\n",
            " 26%|██▌       | 32/125 [02:05<06:09,  3.97s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [02:09<05:51,  3.82s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [02:14<06:14,  4.11s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [02:17<05:52,  3.92s/it]\u001b[A\n",
            " 29%|██▉       | 36/125 [02:20<05:36,  3.78s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [02:24<05:27,  3.72s/it]\u001b[A\n",
            " 30%|███       | 38/125 [02:29<05:52,  4.05s/it]\u001b[A\n",
            " 31%|███       | 39/125 [02:32<05:32,  3.86s/it]\u001b[A\n",
            " 32%|███▏      | 40/125 [02:36<05:18,  3.75s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [02:40<05:33,  3.97s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [02:44<05:27,  3.94s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [02:48<05:12,  3.81s/it]\u001b[A\n",
            " 35%|███▌      | 44/125 [02:51<05:01,  3.72s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [02:56<05:25,  4.07s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [03:00<05:07,  3.89s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [03:03<04:54,  3.77s/it]\u001b[A\n",
            " 38%|███▊      | 48/125 [03:07<04:59,  3.89s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [03:11<05:02,  3.97s/it]\u001b[A\n",
            " 40%|████      | 50/125 [03:15<04:45,  3.81s/it]\u001b[A\n",
            " 41%|████      | 51/125 [03:18<04:35,  3.73s/it]\u001b[A\n",
            " 42%|████▏     | 52/125 [03:23<04:57,  4.08s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [03:27<04:40,  3.90s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [03:30<04:28,  3.78s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [03:34<04:29,  3.85s/it]\u001b[A\n",
            " 45%|████▍     | 56/125 [03:39<04:37,  4.02s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [03:42<04:22,  3.86s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [03:46<04:11,  3.75s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [03:51<04:29,  4.09s/it]\u001b[A\n",
            " 48%|████▊     | 60/125 [03:54<04:14,  3.92s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [03:57<04:02,  3.79s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [04:01<03:59,  3.80s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [04:06<04:12,  4.08s/it]\u001b[A\n",
            " 51%|█████     | 64/125 [04:10<03:58,  3.91s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [04:14<04:09,  4.16s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [04:20<04:33,  4.64s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [04:24<04:10,  4.32s/it]\u001b[A\n",
            " 54%|█████▍    | 68/125 [04:27<03:51,  4.06s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [04:32<04:09,  4.45s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [04:37<04:10,  4.55s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [04:41<03:49,  4.24s/it]\u001b[A\n",
            " 58%|█████▊    | 72/125 [04:44<03:33,  4.03s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [04:49<03:41,  4.25s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [04:53<03:34,  4.20s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [04:57<03:21,  4.03s/it]\u001b[A\n",
            " 61%|██████    | 76/125 [05:01<03:14,  3.98s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [05:05<03:20,  4.18s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [05:09<03:07,  4.00s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [05:12<02:57,  3.85s/it]\u001b[A\n",
            " 64%|██████▍   | 80/125 [05:19<03:27,  4.62s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [05:25<03:42,  5.06s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [05:28<03:16,  4.58s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [05:32<02:58,  4.26s/it]\u001b[A\n",
            " 67%|██████▋   | 84/125 [05:37<03:03,  4.48s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [05:40<02:46,  4.17s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [05:44<02:35,  3.98s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [05:48<02:35,  4.09s/it]\u001b[A\n",
            " 70%|███████   | 88/125 [05:52<02:31,  4.10s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [05:56<02:20,  3.90s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [05:59<02:12,  3.77s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [06:04<02:20,  4.13s/it]\u001b[A\n",
            " 74%|███████▎  | 92/125 [06:08<02:11,  3.98s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [06:11<02:02,  3.83s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [06:15<02:00,  3.88s/it]\u001b[A\n",
            " 76%|███████▌  | 95/125 [06:20<02:01,  4.05s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [06:23<01:52,  3.89s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [06:27<01:46,  3.79s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [06:32<01:51,  4.14s/it]\u001b[A\n",
            " 79%|███████▉  | 99/125 [06:35<01:43,  3.96s/it]\u001b[A\n",
            " 80%|████████  | 100/125 [06:39<01:35,  3.84s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [06:43<01:31,  3.82s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [06:47<01:34,  4.09s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [06:51<01:26,  3.94s/it]\u001b[A\n",
            " 83%|████████▎ | 104/125 [06:54<01:19,  3.80s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [06:59<01:21,  4.07s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [07:03<01:15,  3.98s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [07:06<01:09,  3.86s/it]\u001b[A\n",
            " 86%|████████▋ | 108/125 [07:10<01:04,  3.80s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [07:16<01:11,  4.48s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [07:20<01:04,  4.30s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [07:24<00:57,  4.09s/it]\u001b[A\n",
            " 90%|████████▉ | 112/125 [07:28<00:54,  4.18s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [07:32<00:49,  4.16s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [07:36<00:43,  3.99s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [07:39<00:38,  3.84s/it]\u001b[A\n",
            " 93%|█████████▎| 116/125 [07:44<00:37,  4.18s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [07:48<00:31,  3.98s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [07:51<00:26,  3.84s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [07:56<00:24,  4.01s/it]\u001b[A\n",
            " 96%|█████████▌| 120/125 [08:00<00:20,  4.07s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [08:03<00:15,  3.91s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [08:07<00:11,  3.79s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [08:12<00:08,  4.18s/it]\u001b[A\n",
            " 99%|█████████▉| 124/125 [08:16<00:04,  4.07s/it]\u001b[A\n",
            "100%|██████████| 125/125 [08:19<00:00,  4.00s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss after 250 steps is 0.0788\n",
            "Final Correlation after 250 steps is 0.1140\n",
            "Saving model since validation loss reduced\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'suppress_tokens': []}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            "  8%|▊         | 250/3125 [2:01:40<151:16:21, 189.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 250 is 0.0236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 260/3125 [2:04:41<17:51:16, 22.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 260 is 0.0632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 270/3125 [2:07:45<15:29:33, 19.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 270 is 0.0340\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 280/3125 [2:10:42<14:20:40, 18.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 280 is 0.0166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 290/3125 [2:13:37<13:54:24, 17.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 290 is 0.0370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|▉         | 299/3125 [2:16:20<14:09:12, 18.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:04<10:19,  5.00s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:08<08:29,  4.14s/it]\u001b[A\n",
            "  2%|▏         | 3/125 [00:12<07:54,  3.89s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:16<08:04,  4.01s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:20<08:14,  4.12s/it]\u001b[A\n",
            "  5%|▍         | 6/125 [00:24<07:42,  3.89s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:27<07:24,  3.77s/it]\u001b[A\n",
            "  6%|▋         | 8/125 [00:32<08:07,  4.16s/it]\u001b[A\n",
            "  7%|▋         | 9/125 [00:36<07:45,  4.02s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:40<07:30,  3.92s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:44<07:38,  4.02s/it]\u001b[A\n",
            " 10%|▉         | 12/125 [00:48<07:42,  4.09s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:52<07:19,  3.93s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:55<07:01,  3.79s/it]\u001b[A\n",
            " 12%|█▏        | 15/125 [01:00<07:36,  4.15s/it]\u001b[A\n",
            " 13%|█▎        | 16/125 [01:04<07:12,  3.97s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [01:09<07:41,  4.27s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [01:15<08:54,  5.00s/it]\u001b[A\n",
            " 15%|█▌        | 19/125 [01:19<08:05,  4.58s/it]\u001b[A\n",
            " 16%|█▌        | 20/125 [01:22<07:31,  4.30s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [01:27<07:33,  4.36s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [01:34<08:36,  5.02s/it]\u001b[A\n",
            " 18%|█▊        | 23/125 [01:37<07:59,  4.70s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [01:42<07:47,  4.63s/it]\u001b[A\n",
            " 20%|██        | 25/125 [01:46<07:26,  4.46s/it]\u001b[A\n",
            " 21%|██        | 26/125 [01:50<06:53,  4.17s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [01:54<07:10,  4.39s/it]\u001b[A\n",
            " 22%|██▏       | 28/125 [01:59<07:20,  4.54s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [02:03<06:46,  4.23s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [02:06<06:19,  3.99s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [02:11<06:30,  4.15s/it]\u001b[A\n",
            " 26%|██▌       | 32/125 [02:15<06:17,  4.06s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [02:18<05:59,  3.91s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [02:22<05:46,  3.81s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [02:27<06:07,  4.09s/it]\u001b[A\n",
            " 29%|██▉       | 36/125 [02:30<05:48,  3.91s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [02:34<05:34,  3.80s/it]\u001b[A\n",
            " 30%|███       | 38/125 [02:38<05:53,  4.07s/it]\u001b[A\n",
            " 31%|███       | 39/125 [02:42<05:44,  4.00s/it]\u001b[A\n",
            " 32%|███▏      | 40/125 [02:46<05:30,  3.89s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [02:49<05:21,  3.83s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [02:54<05:41,  4.12s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [02:58<05:22,  3.94s/it]\u001b[A\n",
            " 35%|███▌      | 44/125 [03:01<05:09,  3.82s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [03:06<05:26,  4.08s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [03:10<05:13,  3.96s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [03:13<04:58,  3.82s/it]\u001b[A\n",
            " 38%|███▊      | 48/125 [03:17<04:52,  3.80s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [03:21<05:05,  4.02s/it]\u001b[A\n",
            " 40%|████      | 50/125 [03:25<04:50,  3.87s/it]\u001b[A\n",
            " 41%|████      | 51/125 [03:28<04:38,  3.76s/it]\u001b[A\n",
            " 42%|████▏     | 52/125 [03:33<04:59,  4.10s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [03:37<04:44,  3.95s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [03:40<04:31,  3.82s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [03:44<04:25,  3.80s/it]\u001b[A\n",
            " 45%|████▍     | 56/125 [03:50<05:11,  4.52s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [03:55<05:05,  4.49s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [03:58<04:42,  4.21s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [04:03<04:49,  4.39s/it]\u001b[A\n",
            " 48%|████▊     | 60/125 [04:07<04:28,  4.13s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [04:10<04:12,  3.95s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [04:15<04:21,  4.15s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [04:19<04:10,  4.04s/it]\u001b[A\n",
            " 51%|█████     | 64/125 [04:22<03:57,  3.89s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [04:26<03:56,  3.94s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [04:31<04:06,  4.17s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [04:34<03:50,  3.97s/it]\u001b[A\n",
            " 54%|█████▍    | 68/125 [04:39<04:04,  4.29s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [04:44<04:08,  4.44s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [04:48<03:49,  4.18s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [04:51<03:35,  3.99s/it]\u001b[A\n",
            " 58%|█████▊    | 72/125 [04:56<03:41,  4.17s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [05:00<03:31,  4.07s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [05:03<03:18,  3.90s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [05:07<03:10,  3.81s/it]\u001b[A\n",
            " 61%|██████    | 76/125 [05:12<03:22,  4.14s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [05:15<03:09,  3.95s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [05:19<03:00,  3.84s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [05:23<03:05,  4.04s/it]\u001b[A\n",
            " 64%|██████▍   | 80/125 [05:27<02:59,  3.98s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [05:31<02:49,  3.84s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [05:34<02:40,  3.74s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [05:39<02:51,  4.09s/it]\u001b[A\n",
            " 67%|██████▋   | 84/125 [05:43<02:40,  3.92s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [05:46<02:32,  3.81s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [05:51<02:36,  4.01s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [05:55<02:31,  3.99s/it]\u001b[A\n",
            " 70%|███████   | 88/125 [05:58<02:22,  3.85s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [06:02<02:14,  3.73s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [06:07<02:23,  4.09s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [06:10<02:13,  3.91s/it]\u001b[A\n",
            " 74%|███████▎  | 92/125 [06:14<02:05,  3.80s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [06:18<02:07,  3.98s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [06:22<02:04,  4.03s/it]\u001b[A\n",
            " 76%|███████▌  | 95/125 [06:26<01:56,  3.89s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [06:29<01:49,  3.78s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [06:34<01:55,  4.13s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [06:38<01:46,  3.94s/it]\u001b[A\n",
            " 79%|███████▉  | 99/125 [06:41<01:39,  3.82s/it]\u001b[A\n",
            " 80%|████████  | 100/125 [06:46<01:39,  3.98s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [06:50<01:36,  4.03s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [06:53<01:29,  3.89s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [06:57<01:24,  3.82s/it]\u001b[A\n",
            " 83%|████████▎ | 104/125 [07:02<01:27,  4.16s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [07:05<01:19,  3.95s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [07:09<01:12,  3.82s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [07:13<01:11,  3.96s/it]\u001b[A\n",
            " 86%|████████▋ | 108/125 [07:17<01:08,  4.02s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [07:21<01:02,  3.88s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [07:26<01:04,  4.28s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [07:31<01:00,  4.33s/it]\u001b[A\n",
            " 90%|████████▉ | 112/125 [07:34<00:52,  4.08s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [07:38<00:46,  3.90s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [07:42<00:45,  4.18s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [07:46<00:40,  4.02s/it]\u001b[A\n",
            " 93%|█████████▎| 116/125 [07:50<00:34,  3.87s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [07:53<00:30,  3.81s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [07:58<00:28,  4.09s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [08:01<00:23,  3.92s/it]\u001b[A\n",
            " 96%|█████████▌| 120/125 [08:05<00:18,  3.80s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [08:10<00:16,  4.07s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [08:13<00:11,  3.95s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [08:17<00:07,  3.82s/it]\u001b[A\n",
            " 99%|█████████▉| 124/125 [08:20<00:03,  3.76s/it]\u001b[A\n",
            "100%|██████████| 125/125 [08:25<00:00,  4.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss after 300 steps is 0.0730\n",
            "Final Correlation after 300 steps is 0.2321\n",
            "Saving model since validation loss reduced\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'suppress_tokens': []}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            " 10%|▉         | 300/3125 [2:25:53<144:41:32, 184.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 300 is 0.0312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|▉         | 310/3125 [2:28:57<17:53:29, 22.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 310 is 0.0374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 320/3125 [2:31:55<13:57:47, 17.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 320 is 0.0347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 330/3125 [2:34:51<13:35:48, 17.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 330 is 0.0759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 340/3125 [2:37:51<14:11:55, 18.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 340 is 0.0543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 349/3125 [2:40:36<13:59:27, 18.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:04<09:35,  4.64s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:08<08:33,  4.18s/it]\u001b[A\n",
            "  2%|▏         | 3/125 [00:12<07:53,  3.88s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:15<07:31,  3.73s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:20<08:21,  4.18s/it]\u001b[A\n",
            "  5%|▍         | 6/125 [00:24<07:50,  3.96s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:27<07:29,  3.81s/it]\u001b[A\n",
            "  6%|▋         | 8/125 [00:31<07:48,  4.01s/it]\u001b[A\n",
            "  7%|▋         | 9/125 [00:36<07:47,  4.03s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:39<07:25,  3.87s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:43<07:10,  3.77s/it]\u001b[A\n",
            " 10%|▉         | 12/125 [00:48<07:49,  4.15s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:51<07:23,  3.96s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:55<07:05,  3.83s/it]\u001b[A\n",
            " 12%|█▏        | 15/125 [00:59<07:17,  3.98s/it]\u001b[A\n",
            " 13%|█▎        | 16/125 [01:03<07:20,  4.04s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [01:07<07:01,  3.90s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [01:10<06:46,  3.80s/it]\u001b[A\n",
            " 15%|█▌        | 19/125 [01:15<07:19,  4.15s/it]\u001b[A\n",
            " 16%|█▌        | 20/125 [01:19<06:56,  3.96s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [01:22<06:39,  3.84s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [01:27<06:51,  3.99s/it]\u001b[A\n",
            " 18%|█▊        | 23/125 [01:31<06:53,  4.06s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [01:34<06:33,  3.90s/it]\u001b[A\n",
            " 20%|██        | 25/125 [01:38<06:23,  3.83s/it]\u001b[A\n",
            " 21%|██        | 26/125 [01:43<06:50,  4.14s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [01:47<06:28,  3.96s/it]\u001b[A\n",
            " 22%|██▏       | 28/125 [01:50<06:12,  3.84s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [01:55<06:30,  4.07s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [01:58<06:16,  3.96s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [02:02<06:02,  3.85s/it]\u001b[A\n",
            " 26%|██▌       | 32/125 [02:06<05:58,  3.86s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [02:11<06:18,  4.12s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [02:16<06:38,  4.38s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [02:19<06:11,  4.13s/it]\u001b[A\n",
            " 29%|██▉       | 36/125 [02:24<06:28,  4.37s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [02:28<06:02,  4.12s/it]\u001b[A\n",
            " 30%|███       | 38/125 [02:31<05:44,  3.96s/it]\u001b[A\n",
            " 31%|███       | 39/125 [02:36<05:56,  4.15s/it]\u001b[A\n",
            " 32%|███▏      | 40/125 [02:40<05:43,  4.04s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [02:43<05:27,  3.90s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [02:47<05:19,  3.85s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [02:52<05:36,  4.10s/it]\u001b[A\n",
            " 35%|███▌      | 44/125 [02:55<05:18,  3.94s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [02:59<05:05,  3.81s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [03:03<05:25,  4.12s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [03:07<05:11,  3.99s/it]\u001b[A\n",
            " 38%|███▊      | 48/125 [03:11<04:56,  3.85s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [03:14<04:49,  3.81s/it]\u001b[A\n",
            " 40%|████      | 50/125 [03:19<05:06,  4.08s/it]\u001b[A\n",
            " 41%|████      | 51/125 [03:23<04:50,  3.93s/it]\u001b[A\n",
            " 42%|████▏     | 52/125 [03:26<04:37,  3.80s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [03:31<04:54,  4.09s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [03:35<04:40,  3.96s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [03:39<04:45,  4.08s/it]\u001b[A\n",
            " 45%|████▍     | 56/125 [03:45<05:27,  4.75s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [03:49<05:08,  4.54s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [03:53<04:44,  4.25s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [03:57<04:37,  4.20s/it]\u001b[A\n",
            " 48%|████▊     | 60/125 [04:01<04:37,  4.27s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [04:05<04:20,  4.06s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [04:09<04:06,  3.91s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [04:13<04:21,  4.22s/it]\u001b[A\n",
            " 51%|█████     | 64/125 [04:17<04:05,  4.02s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [04:21<03:52,  3.88s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [04:25<03:52,  3.94s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [04:29<03:55,  4.07s/it]\u001b[A\n",
            " 54%|█████▍    | 68/125 [04:32<03:41,  3.88s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [04:36<03:32,  3.80s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [04:41<03:49,  4.17s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [04:45<03:36,  4.00s/it]\u001b[A\n",
            " 58%|█████▊    | 72/125 [04:48<03:24,  3.86s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [04:53<03:30,  4.06s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [04:58<03:48,  4.49s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [05:02<03:31,  4.23s/it]\u001b[A\n",
            " 61%|██████    | 76/125 [05:06<03:19,  4.08s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [05:10<03:24,  4.27s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [05:14<03:14,  4.14s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [05:18<03:02,  3.96s/it]\u001b[A\n",
            " 64%|██████▍   | 80/125 [05:21<02:53,  3.86s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [05:26<03:03,  4.16s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [05:30<02:51,  3.99s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [05:33<02:42,  3.87s/it]\u001b[A\n",
            " 67%|██████▋   | 84/125 [05:38<02:49,  4.14s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [05:42<02:39,  3.99s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [05:45<02:31,  3.88s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [05:49<02:28,  3.92s/it]\u001b[A\n",
            " 70%|███████   | 88/125 [05:54<02:34,  4.17s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [05:58<02:23,  3.98s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [06:01<02:15,  3.87s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [06:06<02:21,  4.17s/it]\u001b[A\n",
            " 74%|███████▎  | 92/125 [06:10<02:11,  3.98s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [06:13<02:02,  3.84s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [06:17<02:01,  3.92s/it]\u001b[A\n",
            " 76%|███████▌  | 95/125 [06:22<02:02,  4.08s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [06:25<01:53,  3.92s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [06:29<01:46,  3.80s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [06:34<01:52,  4.15s/it]\u001b[A\n",
            " 79%|███████▉  | 99/125 [06:37<01:43,  3.98s/it]\u001b[A\n",
            " 80%|████████  | 100/125 [06:41<01:36,  3.86s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [06:45<01:33,  3.88s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [06:49<01:33,  4.07s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [06:53<01:26,  3.92s/it]\u001b[A\n",
            " 83%|████████▎ | 104/125 [06:57<01:19,  3.79s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [07:01<01:22,  4.12s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [07:05<01:16,  4.00s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [07:09<01:09,  3.87s/it]\u001b[A\n",
            " 86%|████████▋ | 108/125 [07:12<01:04,  3.78s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [07:17<01:05,  4.09s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [07:21<00:58,  3.93s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [07:24<00:53,  3.83s/it]\u001b[A\n",
            " 90%|████████▉ | 112/125 [07:29<00:53,  4.11s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [07:34<00:53,  4.45s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [07:38<00:45,  4.17s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [07:42<00:42,  4.28s/it]\u001b[A\n",
            " 93%|█████████▎| 116/125 [07:46<00:37,  4.14s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [07:50<00:31,  3.95s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [07:53<00:27,  3.87s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [07:58<00:25,  4.21s/it]\u001b[A\n",
            " 96%|█████████▌| 120/125 [08:02<00:20,  4.01s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [08:05<00:15,  3.88s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [08:10<00:12,  4.19s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [08:14<00:08,  4.05s/it]\u001b[A\n",
            " 99%|█████████▉| 124/125 [08:18<00:03,  3.90s/it]\u001b[A\n",
            "100%|██████████| 125/125 [08:21<00:00,  4.02s/it]\n",
            " 11%|█         | 350/3125 [2:49:15<129:48:58, 168.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss after 350 steps is 0.0754\n",
            "Final Correlation after 350 steps is 0.2856\n",
            "No improvement in eval loss for 1 evaluations\n",
            "Loss at step 350 is 0.0603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 360/3125 [2:52:16<17:03:25, 22.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 360 is 0.1010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 370/3125 [2:55:13<13:25:10, 17.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 370 is 0.0330\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 380/3125 [2:58:11<13:38:14, 17.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 380 is 0.0654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 390/3125 [3:01:11<13:44:55, 18.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 390 is 0.0276\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 399/3125 [3:03:51<13:19:31, 17.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:03<07:17,  3.53s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:07<07:17,  3.56s/it]\u001b[A\n",
            "  2%|▏         | 3/125 [00:11<07:32,  3.71s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:16<08:50,  4.38s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:20<08:34,  4.28s/it]\u001b[A\n",
            "  5%|▍         | 6/125 [00:24<08:06,  4.09s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:28<08:27,  4.30s/it]\u001b[A\n",
            "  6%|▋         | 8/125 [00:32<07:54,  4.06s/it]\u001b[A\n",
            "  7%|▋         | 9/125 [00:36<07:33,  3.91s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:40<08:00,  4.18s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:44<07:39,  4.03s/it]\u001b[A\n",
            " 10%|▉         | 12/125 [00:48<07:17,  3.87s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:51<07:07,  3.82s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:56<07:36,  4.11s/it]\u001b[A\n",
            " 12%|█▏        | 15/125 [01:00<07:13,  3.94s/it]\u001b[A\n",
            " 13%|█▎        | 16/125 [01:03<06:53,  3.79s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [01:08<07:16,  4.04s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [01:11<07:04,  3.97s/it]\u001b[A\n",
            " 15%|█▌        | 19/125 [01:15<06:48,  3.85s/it]\u001b[A\n",
            " 16%|█▌        | 20/125 [01:19<06:37,  3.79s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [01:24<07:06,  4.10s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [01:27<06:47,  3.96s/it]\u001b[A\n",
            " 18%|█▊        | 23/125 [01:31<06:33,  3.86s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [01:36<06:57,  4.13s/it]\u001b[A\n",
            " 20%|██        | 25/125 [01:39<06:43,  4.04s/it]\u001b[A\n",
            " 21%|██        | 26/125 [01:43<06:25,  3.89s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [01:47<06:19,  3.87s/it]\u001b[A\n",
            " 22%|██▏       | 28/125 [01:52<06:45,  4.18s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [01:55<06:23,  4.00s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [01:59<06:07,  3.86s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [02:03<06:27,  4.12s/it]\u001b[A\n",
            " 26%|██▌       | 32/125 [02:07<06:14,  4.03s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [02:11<05:56,  3.88s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [02:14<05:46,  3.81s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [02:19<06:13,  4.15s/it]\u001b[A\n",
            " 29%|██▉       | 36/125 [02:23<05:55,  4.00s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [02:27<05:39,  3.86s/it]\u001b[A\n",
            " 30%|███       | 38/125 [02:31<05:57,  4.11s/it]\u001b[A\n",
            " 31%|███       | 39/125 [02:35<05:46,  4.03s/it]\u001b[A\n",
            " 32%|███▏      | 40/125 [02:39<05:30,  3.89s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [02:42<05:20,  3.82s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [02:47<05:45,  4.16s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [02:51<05:26,  3.99s/it]\u001b[A\n",
            " 35%|███▌      | 44/125 [02:55<05:30,  4.09s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [03:01<06:06,  4.58s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [03:05<05:38,  4.29s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [03:08<05:16,  4.06s/it]\u001b[A\n",
            " 38%|███▊      | 48/125 [03:12<05:09,  4.02s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [03:16<05:14,  4.13s/it]\u001b[A\n",
            " 40%|████      | 50/125 [03:20<04:58,  3.98s/it]\u001b[A\n",
            " 41%|████      | 51/125 [03:24<04:51,  3.94s/it]\u001b[A\n",
            " 42%|████▏     | 52/125 [03:29<05:11,  4.27s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [03:32<04:52,  4.06s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [03:36<04:38,  3.92s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [03:40<04:43,  4.05s/it]\u001b[A\n",
            " 45%|████▍     | 56/125 [03:45<04:44,  4.13s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [03:48<04:29,  3.97s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [03:52<04:17,  3.84s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [03:57<04:36,  4.18s/it]\u001b[A\n",
            " 48%|████▊     | 60/125 [04:00<04:18,  3.98s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [04:04<04:05,  3.84s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [04:08<04:07,  3.94s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [04:12<04:10,  4.05s/it]\u001b[A\n",
            " 51%|█████     | 64/125 [04:16<03:57,  3.90s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [04:19<03:46,  3.78s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [04:24<04:00,  4.08s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [04:29<04:16,  4.43s/it]\u001b[A\n",
            " 54%|█████▍    | 68/125 [04:35<04:36,  4.84s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [04:40<04:22,  4.69s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [04:43<03:58,  4.33s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [04:47<03:40,  4.09s/it]\u001b[A\n",
            " 58%|█████▊    | 72/125 [04:52<03:50,  4.34s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [04:55<03:33,  4.10s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [04:59<03:20,  3.93s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [05:03<03:16,  3.93s/it]\u001b[A\n",
            " 61%|██████    | 76/125 [05:07<03:20,  4.10s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [05:11<03:08,  3.93s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [05:14<02:59,  3.82s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [05:19<03:11,  4.16s/it]\u001b[A\n",
            " 64%|██████▍   | 80/125 [05:23<02:59,  3.99s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [05:26<02:49,  3.84s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [05:30<02:46,  3.87s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [05:36<03:07,  4.46s/it]\u001b[A\n",
            " 67%|██████▋   | 84/125 [05:40<02:54,  4.25s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [05:43<02:41,  4.04s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [05:48<02:50,  4.37s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [05:52<02:37,  4.13s/it]\u001b[A\n",
            " 70%|███████   | 88/125 [05:55<02:26,  3.95s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [06:00<02:24,  4.01s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [06:04<02:22,  4.07s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [06:07<02:13,  3.91s/it]\u001b[A\n",
            " 74%|███████▎  | 92/125 [06:11<02:05,  3.81s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [06:16<02:12,  4.16s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [06:20<02:03,  3.99s/it]\u001b[A\n",
            " 76%|███████▌  | 95/125 [06:23<01:56,  3.88s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [06:27<01:53,  3.93s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [06:32<01:54,  4.08s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [06:35<01:46,  3.93s/it]\u001b[A\n",
            " 79%|███████▉  | 99/125 [06:39<01:39,  3.81s/it]\u001b[A\n",
            " 80%|████████  | 100/125 [06:44<01:44,  4.17s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [06:47<01:35,  4.00s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [06:51<01:28,  3.87s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [06:55<01:26,  3.94s/it]\u001b[A\n",
            " 83%|████████▎ | 104/125 [06:59<01:25,  4.06s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [07:03<01:17,  3.86s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [07:06<01:11,  3.76s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [07:11<01:13,  4.10s/it]\u001b[A\n",
            " 86%|████████▋ | 108/125 [07:15<01:07,  3.95s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [07:18<01:01,  3.84s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [07:22<00:58,  3.90s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [07:27<00:57,  4.09s/it]\u001b[A\n",
            " 90%|████████▉ | 112/125 [07:30<00:51,  3.93s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [07:34<00:45,  3.82s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [07:39<00:45,  4.15s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [07:42<00:39,  3.96s/it]\u001b[A\n",
            " 93%|█████████▎| 116/125 [07:46<00:34,  3.84s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [07:50<00:31,  3.89s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [07:55<00:28,  4.12s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [07:58<00:23,  3.95s/it]\u001b[A\n",
            " 96%|█████████▌| 120/125 [08:02<00:19,  3.83s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [08:07<00:16,  4.14s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [08:10<00:11,  3.95s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [08:15<00:08,  4.27s/it]\u001b[A\n",
            " 99%|█████████▉| 124/125 [08:20<00:04,  4.43s/it]\u001b[A\n",
            "100%|██████████| 125/125 [08:24<00:00,  4.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss after 400 steps is 0.0706\n",
            "Final Correlation after 400 steps is 0.3283\n",
            "Saving model since validation loss reduced\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'suppress_tokens': []}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            " 13%|█▎        | 400/3125 [3:13:25<139:44:52, 184.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 400 is 0.0890\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 410/3125 [3:16:35<17:16:47, 22.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 410 is 0.0476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 420/3125 [3:19:34<13:34:36, 18.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 420 is 0.0445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 430/3125 [3:22:30<13:00:49, 17.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 430 is 0.0531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 440/3125 [3:25:39<13:57:56, 18.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 440 is 0.0693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 449/3125 [3:28:17<13:12:01, 17.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:04<08:25,  4.07s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:07<07:37,  3.72s/it]\u001b[A\n",
            "  2%|▏         | 3/125 [00:11<07:19,  3.61s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:15<08:15,  4.10s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:19<07:48,  3.91s/it]\u001b[A\n",
            "  5%|▍         | 6/125 [00:23<07:33,  3.81s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:27<07:47,  3.96s/it]\u001b[A\n",
            "  6%|▋         | 8/125 [00:31<07:51,  4.03s/it]\u001b[A\n",
            "  7%|▋         | 9/125 [00:34<07:25,  3.84s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:38<07:12,  3.76s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:43<07:50,  4.13s/it]\u001b[A\n",
            " 10%|▉         | 12/125 [00:46<07:25,  3.94s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:50<07:07,  3.81s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:54<07:16,  3.93s/it]\u001b[A\n",
            " 12%|█▏        | 15/125 [00:58<07:23,  4.03s/it]\u001b[A\n",
            " 13%|█▎        | 16/125 [01:02<07:03,  3.89s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [01:06<06:47,  3.78s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [01:11<07:24,  4.15s/it]\u001b[A\n",
            " 15%|█▌        | 19/125 [01:14<07:00,  3.96s/it]\u001b[A\n",
            " 16%|█▌        | 20/125 [01:18<06:43,  3.84s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [01:22<06:42,  3.87s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [01:26<06:55,  4.03s/it]\u001b[A\n",
            " 18%|█▊        | 23/125 [01:30<06:36,  3.88s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [01:33<06:20,  3.76s/it]\u001b[A\n",
            " 20%|██        | 25/125 [01:38<06:40,  4.00s/it]\u001b[A\n",
            " 21%|██        | 26/125 [01:41<06:28,  3.93s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [01:45<06:11,  3.79s/it]\u001b[A\n",
            " 22%|██▏       | 28/125 [01:48<05:59,  3.70s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [01:53<06:23,  4.00s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [01:58<06:37,  4.19s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [02:01<06:23,  4.08s/it]\u001b[A\n",
            " 26%|██▌       | 32/125 [02:06<06:42,  4.33s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [02:10<06:15,  4.08s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [02:13<05:56,  3.91s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [02:18<06:08,  4.09s/it]\u001b[A\n",
            " 29%|██▉       | 36/125 [02:22<06:05,  4.10s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [02:26<05:54,  4.02s/it]\u001b[A\n",
            " 30%|███       | 38/125 [02:30<05:43,  3.95s/it]\u001b[A\n",
            " 31%|███       | 39/125 [02:35<06:04,  4.24s/it]\u001b[A\n",
            " 32%|███▏      | 40/125 [02:38<05:42,  4.03s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [02:42<05:34,  3.99s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [02:47<05:49,  4.22s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [02:50<05:33,  4.07s/it]\u001b[A\n",
            " 35%|███▌      | 44/125 [02:54<05:16,  3.91s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [02:58<05:07,  3.85s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [03:02<05:26,  4.13s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [03:06<05:09,  3.97s/it]\u001b[A\n",
            " 38%|███▊      | 48/125 [03:10<04:55,  3.84s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [03:14<05:12,  4.11s/it]\u001b[A\n",
            " 40%|████      | 50/125 [03:18<04:59,  3.99s/it]\u001b[A\n",
            " 41%|████      | 51/125 [03:22<04:45,  3.86s/it]\u001b[A\n",
            " 42%|████▏     | 52/125 [03:25<04:36,  3.79s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [03:30<04:56,  4.12s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [03:34<04:41,  3.96s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [03:37<04:28,  3.84s/it]\u001b[A\n",
            " 45%|████▍     | 56/125 [03:42<04:40,  4.06s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [03:46<04:33,  4.02s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [03:49<04:21,  3.90s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [03:53<04:08,  3.76s/it]\u001b[A\n",
            " 48%|████▊     | 60/125 [03:58<04:29,  4.14s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [04:01<04:12,  3.95s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [04:05<04:02,  3.85s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [04:10<04:23,  4.25s/it]\u001b[A\n",
            " 51%|█████     | 64/125 [04:15<04:25,  4.35s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [04:18<04:06,  4.11s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [04:22<03:54,  3.97s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [04:27<04:09,  4.31s/it]\u001b[A\n",
            " 54%|█████▍    | 68/125 [04:31<03:56,  4.15s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [04:36<04:03,  4.35s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [04:41<04:08,  4.52s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [04:44<03:47,  4.22s/it]\u001b[A\n",
            " 58%|█████▊    | 72/125 [04:48<03:33,  4.02s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [04:52<03:30,  4.04s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [04:56<03:33,  4.18s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [05:00<03:20,  4.01s/it]\u001b[A\n",
            " 61%|██████    | 76/125 [05:03<03:10,  3.89s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [05:08<03:21,  4.19s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [05:12<03:07,  3.99s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [05:15<02:57,  3.86s/it]\u001b[A\n",
            " 64%|██████▍   | 80/125 [05:20<02:58,  3.97s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [05:28<03:56,  5.38s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [05:32<03:26,  4.79s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [05:35<03:05,  4.42s/it]\u001b[A\n",
            " 67%|██████▋   | 84/125 [05:40<03:07,  4.58s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [05:44<02:50,  4.27s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [05:47<02:38,  4.06s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [05:51<02:34,  4.05s/it]\u001b[A\n",
            " 70%|███████   | 88/125 [05:56<02:34,  4.18s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [05:59<02:23,  4.00s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [06:03<02:15,  3.86s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [06:08<02:21,  4.15s/it]\u001b[A\n",
            " 74%|███████▎  | 92/125 [06:11<02:10,  3.96s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [06:15<02:02,  3.83s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [06:19<02:01,  3.91s/it]\u001b[A\n",
            " 76%|███████▌  | 95/125 [06:23<02:01,  4.06s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [06:27<01:53,  3.90s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [06:30<01:46,  3.79s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [06:35<01:51,  4.15s/it]\u001b[A\n",
            " 79%|███████▉  | 99/125 [06:39<01:43,  3.99s/it]\u001b[A\n",
            " 80%|████████  | 100/125 [06:43<01:37,  3.89s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [06:47<01:33,  3.92s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [06:51<01:33,  4.04s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [06:54<01:25,  3.88s/it]\u001b[A\n",
            " 83%|████████▎ | 104/125 [06:58<01:19,  3.77s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [07:03<01:22,  4.14s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [07:08<01:21,  4.28s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [07:11<01:14,  4.14s/it]\u001b[A\n",
            " 86%|████████▋ | 108/125 [07:16<01:13,  4.31s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [07:20<01:06,  4.14s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [07:24<01:00,  4.01s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [07:27<00:55,  3.95s/it]\u001b[A\n",
            " 90%|████████▉ | 112/125 [07:32<00:54,  4.17s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [07:36<00:47,  3.98s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [07:39<00:42,  3.86s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [07:44<00:41,  4.15s/it]\u001b[A\n",
            " 93%|█████████▎| 116/125 [07:48<00:36,  4.01s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [07:51<00:31,  3.88s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [07:55<00:26,  3.81s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [08:00<00:24,  4.08s/it]\u001b[A\n",
            " 96%|█████████▌| 120/125 [08:03<00:19,  3.92s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [08:07<00:15,  3.78s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [08:11<00:12,  4.02s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [08:15<00:07,  3.92s/it]\u001b[A\n",
            " 99%|█████████▉| 124/125 [08:18<00:03,  3.79s/it]\u001b[A\n",
            "100%|██████████| 125/125 [08:22<00:00,  4.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss after 450 steps is 0.0683\n",
            "Final Correlation after 450 steps is 0.3665\n",
            "Saving model since validation loss reduced\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'suppress_tokens': []}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            " 14%|█▍        | 450/3125 [3:38:01<139:32:10, 187.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 450 is 0.0303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 460/3125 [3:41:01<16:42:35, 22.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 460 is 0.0129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 470/3125 [3:43:57<13:13:15, 17.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 470 is 0.0227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 480/3125 [3:47:01<13:19:52, 18.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 480 is 0.0305\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 490/3125 [3:50:15<13:52:04, 18.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 490 is 0.0408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 499/3125 [3:52:55<13:00:50, 17.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:04<08:18,  4.02s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:08<08:49,  4.30s/it]\u001b[A\n",
            "  2%|▏         | 3/125 [00:13<09:28,  4.66s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:17<08:54,  4.42s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:22<08:54,  4.45s/it]\u001b[A\n",
            "  5%|▍         | 6/125 [00:25<08:15,  4.16s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:29<07:46,  3.96s/it]\u001b[A\n",
            "  6%|▋         | 8/125 [00:34<08:21,  4.29s/it]\u001b[A\n",
            "  7%|▋         | 9/125 [00:37<07:48,  4.04s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:41<07:28,  3.90s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:45<07:28,  3.93s/it]\u001b[A\n",
            " 10%|▉         | 12/125 [00:49<07:43,  4.10s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:53<07:22,  3.95s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:57<07:04,  3.82s/it]\u001b[A\n",
            " 12%|█▏        | 15/125 [01:02<07:44,  4.22s/it]\u001b[A\n",
            " 13%|█▎        | 16/125 [01:05<07:20,  4.04s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [01:09<06:57,  3.86s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [01:12<06:47,  3.81s/it]\u001b[A\n",
            " 15%|█▌        | 19/125 [01:17<07:15,  4.11s/it]\u001b[A\n",
            " 16%|█▌        | 20/125 [01:21<06:55,  3.95s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [01:24<06:38,  3.83s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [01:29<07:02,  4.10s/it]\u001b[A\n",
            " 18%|█▊        | 23/125 [01:33<06:47,  4.00s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [01:36<06:29,  3.86s/it]\u001b[A\n",
            " 20%|██        | 25/125 [01:40<06:17,  3.78s/it]\u001b[A\n",
            " 21%|██        | 26/125 [01:45<06:48,  4.13s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [01:48<06:26,  3.94s/it]\u001b[A\n",
            " 22%|██▏       | 28/125 [01:52<06:10,  3.82s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [01:56<06:27,  4.04s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [02:01<06:32,  4.13s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [02:04<06:11,  3.95s/it]\u001b[A\n",
            " 26%|██▌       | 32/125 [02:08<06:02,  3.89s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [02:13<06:23,  4.17s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [02:17<06:03,  4.00s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [02:20<05:47,  3.86s/it]\u001b[A\n",
            " 29%|██▉       | 36/125 [02:25<06:09,  4.16s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [02:29<05:54,  4.03s/it]\u001b[A\n",
            " 30%|███       | 38/125 [02:32<05:40,  3.92s/it]\u001b[A\n",
            " 31%|███       | 39/125 [02:36<05:33,  3.87s/it]\u001b[A\n",
            " 32%|███▏      | 40/125 [02:41<06:07,  4.32s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [02:46<06:05,  4.35s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [02:49<05:40,  4.11s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [02:54<05:58,  4.37s/it]\u001b[A\n",
            " 35%|███▌      | 44/125 [02:58<05:34,  4.13s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [03:02<05:16,  3.96s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [03:06<05:31,  4.19s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [03:10<05:17,  4.07s/it]\u001b[A\n",
            " 38%|███▊      | 48/125 [03:14<05:00,  3.91s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [03:17<04:51,  3.83s/it]\u001b[A\n",
            " 40%|████      | 50/125 [03:22<05:09,  4.13s/it]\u001b[A\n",
            " 41%|████      | 51/125 [03:26<04:52,  3.96s/it]\u001b[A\n",
            " 42%|████▏     | 52/125 [03:29<04:40,  3.84s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [03:38<06:27,  5.38s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [03:42<05:50,  4.93s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [03:46<05:18,  4.56s/it]\u001b[A\n",
            " 45%|████▍     | 56/125 [03:49<04:54,  4.27s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [03:54<05:01,  4.44s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [03:58<04:40,  4.18s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [04:01<04:24,  4.00s/it]\u001b[A\n",
            " 48%|████▊     | 60/125 [04:06<04:34,  4.22s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [04:10<04:21,  4.08s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [04:13<04:08,  3.94s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [04:17<04:00,  3.88s/it]\u001b[A\n",
            " 51%|█████     | 64/125 [04:22<04:14,  4.17s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [04:25<03:57,  3.96s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [04:29<03:46,  3.84s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [04:34<04:01,  4.16s/it]\u001b[A\n",
            " 54%|█████▍    | 68/125 [04:38<03:47,  3.99s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [04:41<03:35,  3.85s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [04:45<03:32,  3.86s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [04:50<03:41,  4.11s/it]\u001b[A\n",
            " 58%|█████▊    | 72/125 [04:53<03:28,  3.94s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [04:57<03:19,  3.83s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [05:02<03:31,  4.14s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [05:05<03:20,  4.00s/it]\u001b[A\n",
            " 61%|██████    | 76/125 [05:09<03:08,  3.84s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [05:14<03:25,  4.28s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [05:19<03:30,  4.48s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [05:23<03:12,  4.19s/it]\u001b[A\n",
            " 64%|██████▍   | 80/125 [05:26<02:59,  3.99s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [05:31<03:06,  4.24s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [05:35<02:55,  4.09s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [05:38<02:44,  3.93s/it]\u001b[A\n",
            " 67%|██████▋   | 84/125 [05:42<02:38,  3.86s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [05:47<02:45,  4.15s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [05:50<02:34,  3.96s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [05:54<02:25,  3.84s/it]\u001b[A\n",
            " 70%|███████   | 88/125 [05:58<02:31,  4.08s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [06:02<02:24,  4.01s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [06:06<02:15,  3.86s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [06:09<02:08,  3.78s/it]\u001b[A\n",
            " 74%|███████▎  | 92/125 [06:14<02:16,  4.14s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [06:18<02:07,  3.98s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [06:21<01:59,  3.85s/it]\u001b[A\n",
            " 76%|███████▌  | 95/125 [06:26<02:02,  4.08s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [06:30<01:56,  4.03s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [06:34<01:49,  3.91s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [06:37<01:42,  3.79s/it]\u001b[A\n",
            " 79%|███████▉  | 99/125 [06:42<01:48,  4.16s/it]\u001b[A\n",
            " 80%|████████  | 100/125 [06:46<01:40,  4.01s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [06:49<01:32,  3.87s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [06:54<01:33,  4.08s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [06:58<01:29,  4.06s/it]\u001b[A\n",
            " 83%|████████▎ | 104/125 [07:02<01:22,  3.93s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [07:05<01:15,  3.79s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [07:10<01:18,  4.14s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [07:14<01:11,  3.99s/it]\u001b[A\n",
            " 86%|████████▋ | 108/125 [07:17<01:06,  3.92s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [07:22<01:07,  4.23s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [07:26<01:01,  4.13s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [07:30<00:55,  3.97s/it]\u001b[A\n",
            " 90%|████████▉ | 112/125 [07:34<00:50,  3.90s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [07:38<00:49,  4.12s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [07:42<00:43,  3.97s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [07:47<00:43,  4.36s/it]\u001b[A\n",
            " 93%|█████████▎| 116/125 [07:52<00:40,  4.53s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [07:56<00:33,  4.25s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [07:59<00:28,  4.03s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [08:04<00:25,  4.27s/it]\u001b[A\n",
            " 96%|█████████▌| 120/125 [08:08<00:20,  4.13s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [08:11<00:15,  3.99s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [08:15<00:11,  3.92s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [08:20<00:08,  4.19s/it]\u001b[A\n",
            " 99%|█████████▉| 124/125 [08:24<00:04,  4.01s/it]\u001b[A\n",
            "100%|██████████| 125/125 [08:27<00:00,  4.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss after 500 steps is 0.0654\n",
            "Final Correlation after 500 steps is 0.4007\n",
            "Saving model since validation loss reduced\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'suppress_tokens': []}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            " 16%|█▌        | 500/3125 [4:03:02<141:53:07, 194.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 500 is 0.0997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▋        | 510/3125 [4:06:04<16:55:08, 23.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 510 is 0.0290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 520/3125 [4:09:07<13:09:57, 18.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 520 is 0.0314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 530/3125 [4:12:06<13:08:37, 18.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 530 is 0.0657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 540/3125 [4:15:01<12:23:46, 17.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 540 is 0.1028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 549/3125 [4:17:43<12:46:28, 17.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:03<07:22,  3.57s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:08<08:59,  4.39s/it]\u001b[A\n",
            "  2%|▏         | 3/125 [00:12<08:18,  4.09s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:17<08:50,  4.39s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:22<09:09,  4.58s/it]\u001b[A\n",
            "  5%|▍         | 6/125 [00:25<08:25,  4.25s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:29<07:54,  4.02s/it]\u001b[A\n",
            "  6%|▋         | 8/125 [00:33<07:58,  4.09s/it]\u001b[A\n",
            "  7%|▋         | 9/125 [00:37<08:01,  4.15s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:41<07:36,  3.97s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:44<07:17,  3.84s/it]\u001b[A\n",
            " 10%|▉         | 12/125 [00:49<07:56,  4.22s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:53<07:31,  4.03s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:57<07:12,  3.90s/it]\u001b[A\n",
            " 12%|█▏        | 15/125 [01:01<07:19,  4.00s/it]\u001b[A\n",
            " 13%|█▎        | 16/125 [01:05<07:24,  4.08s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [01:09<07:02,  3.91s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [01:12<06:46,  3.80s/it]\u001b[A\n",
            " 15%|█▌        | 19/125 [01:17<07:20,  4.16s/it]\u001b[A\n",
            " 16%|█▌        | 20/125 [01:21<07:09,  4.09s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [01:25<06:50,  3.95s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [01:29<07:04,  4.12s/it]\u001b[A\n",
            " 18%|█▊        | 23/125 [01:33<07:05,  4.17s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [01:37<06:43,  3.99s/it]\u001b[A\n",
            " 20%|██        | 25/125 [01:41<06:27,  3.87s/it]\u001b[A\n",
            " 21%|██        | 26/125 [01:46<06:55,  4.20s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [01:49<06:32,  4.00s/it]\u001b[A\n",
            " 22%|██▏       | 28/125 [01:53<06:15,  3.87s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [01:57<06:33,  4.10s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [02:01<06:24,  4.04s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [02:05<06:06,  3.90s/it]\u001b[A\n",
            " 26%|██▌       | 32/125 [02:08<05:53,  3.80s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [02:13<06:23,  4.17s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [02:17<06:04,  4.00s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [02:21<05:49,  3.88s/it]\u001b[A\n",
            " 29%|██▉       | 36/125 [02:25<06:07,  4.13s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [02:29<05:58,  4.08s/it]\u001b[A\n",
            " 30%|███       | 38/125 [02:33<05:41,  3.93s/it]\u001b[A\n",
            " 31%|███       | 39/125 [02:36<05:26,  3.79s/it]\u001b[A\n",
            " 32%|███▏      | 40/125 [02:43<06:24,  4.52s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [02:47<06:08,  4.39s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [02:50<05:42,  4.13s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [02:54<05:39,  4.14s/it]\u001b[A\n",
            " 35%|███▌      | 44/125 [02:59<05:39,  4.19s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [03:04<05:52,  4.41s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [03:08<05:40,  4.31s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [03:12<05:41,  4.38s/it]\u001b[A\n",
            " 38%|███▊      | 48/125 [03:16<05:18,  4.14s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [03:19<05:02,  3.98s/it]\u001b[A\n",
            " 40%|████      | 50/125 [03:24<05:22,  4.30s/it]\u001b[A\n",
            " 41%|████      | 51/125 [03:28<05:02,  4.09s/it]\u001b[A\n",
            " 42%|████▏     | 52/125 [03:32<04:46,  3.93s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [03:36<04:47,  4.00s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [03:41<04:59,  4.22s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [03:44<04:43,  4.05s/it]\u001b[A\n",
            " 45%|████▍     | 56/125 [03:48<04:28,  3.89s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [03:53<04:46,  4.22s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [03:56<04:32,  4.06s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [04:00<04:19,  3.94s/it]\u001b[A\n",
            " 48%|████▊     | 60/125 [04:04<04:23,  4.05s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [04:09<04:23,  4.12s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [04:12<04:10,  3.97s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [04:16<03:57,  3.84s/it]\u001b[A\n",
            " 51%|█████     | 64/125 [04:21<04:15,  4.19s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [04:24<04:00,  4.00s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [04:28<03:46,  3.83s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [04:32<03:47,  3.93s/it]\u001b[A\n",
            " 54%|█████▍    | 68/125 [04:36<03:50,  4.05s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [04:40<03:37,  3.89s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [04:43<03:28,  3.80s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [04:48<03:44,  4.15s/it]\u001b[A\n",
            " 58%|█████▊    | 72/125 [04:52<03:32,  4.00s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [04:56<03:22,  3.89s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [05:00<03:27,  4.07s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [05:04<03:26,  4.13s/it]\u001b[A\n",
            " 61%|██████    | 76/125 [05:10<03:37,  4.43s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [05:14<03:30,  4.38s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [05:18<03:26,  4.40s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [05:22<03:11,  4.15s/it]\u001b[A\n",
            " 64%|██████▍   | 80/125 [05:25<02:59,  3.99s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [05:31<03:09,  4.32s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [05:34<02:57,  4.12s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [05:38<02:47,  3.99s/it]\u001b[A\n",
            " 67%|██████▋   | 84/125 [05:42<02:51,  4.17s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [05:47<02:48,  4.21s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [05:50<02:37,  4.04s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [05:54<02:29,  3.94s/it]\u001b[A\n",
            " 70%|███████   | 88/125 [05:59<02:38,  4.29s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [06:03<02:26,  4.06s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [06:06<02:17,  3.92s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [06:11<02:21,  4.15s/it]\u001b[A\n",
            " 74%|███████▎  | 92/125 [06:15<02:15,  4.11s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [06:19<02:06,  3.95s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [06:22<01:59,  3.86s/it]\u001b[A\n",
            " 76%|███████▌  | 95/125 [06:27<02:04,  4.16s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [06:31<01:55,  4.00s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [06:34<01:48,  3.88s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [06:39<01:51,  4.14s/it]\u001b[A\n",
            " 79%|███████▉  | 99/125 [06:43<01:44,  4.03s/it]\u001b[A\n",
            " 80%|████████  | 100/125 [06:47<01:37,  3.92s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [06:50<01:33,  3.91s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [06:55<01:35,  4.17s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [06:59<01:28,  4.00s/it]\u001b[A\n",
            " 83%|████████▎ | 104/125 [07:02<01:21,  3.87s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [07:10<01:38,  4.95s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [07:14<01:27,  4.62s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [07:17<01:17,  4.32s/it]\u001b[A\n",
            " 86%|████████▋ | 108/125 [07:21<01:11,  4.20s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [07:26<01:09,  4.36s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [07:30<01:03,  4.26s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [07:35<01:02,  4.45s/it]\u001b[A\n",
            " 90%|████████▉ | 112/125 [07:40<00:59,  4.57s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [07:43<00:51,  4.27s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [07:47<00:44,  4.07s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [07:52<00:43,  4.38s/it]\u001b[A\n",
            " 93%|█████████▎| 116/125 [07:56<00:38,  4.24s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [08:00<00:32,  4.05s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [08:03<00:28,  4.00s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [08:08<00:25,  4.21s/it]\u001b[A\n",
            " 96%|█████████▌| 120/125 [08:12<00:20,  4.02s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [08:15<00:15,  3.90s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [08:20<00:12,  4.24s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [08:24<00:08,  4.07s/it]\u001b[A\n",
            " 99%|█████████▉| 124/125 [08:28<00:03,  3.93s/it]\u001b[A\n",
            "100%|██████████| 125/125 [08:32<00:00,  4.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss after 550 steps is 0.0641\n",
            "Final Correlation after 550 steps is 0.4149\n",
            "Saving model since validation loss reduced\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'suppress_tokens': []}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            " 18%|█▊        | 550/3125 [4:27:55<140:23:29, 196.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 550 is 0.0099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 560/3125 [4:30:59<16:31:30, 23.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 560 is 1.6682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 570/3125 [4:33:59<12:45:11, 17.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 570 is 0.0759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▊        | 580/3125 [4:36:59<12:37:05, 17.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 580 is 0.0137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 590/3125 [4:40:02<12:45:48, 18.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 590 is 0.0097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 599/3125 [4:42:41<12:38:18, 18.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/125 [00:03<07:20,  3.55s/it]\u001b[A\n",
            "  2%|▏         | 2/125 [00:06<07:07,  3.47s/it]\u001b[A\n",
            "  2%|▏         | 3/125 [00:11<08:22,  4.12s/it]\u001b[A\n",
            "  3%|▎         | 4/125 [00:15<07:47,  3.86s/it]\u001b[A\n",
            "  4%|▍         | 5/125 [00:18<07:27,  3.73s/it]\u001b[A\n",
            "  5%|▍         | 6/125 [00:22<07:33,  3.81s/it]\u001b[A\n",
            "  6%|▌         | 7/125 [00:27<07:55,  4.03s/it]\u001b[A\n",
            "  6%|▋         | 8/125 [00:30<07:32,  3.87s/it]\u001b[A\n",
            "  7%|▋         | 9/125 [00:34<07:13,  3.74s/it]\u001b[A\n",
            "  8%|▊         | 10/125 [00:39<08:15,  4.31s/it]\u001b[A\n",
            "  9%|▉         | 11/125 [00:43<07:43,  4.06s/it]\u001b[A\n",
            " 10%|▉         | 12/125 [00:46<07:20,  3.90s/it]\u001b[A\n",
            " 10%|█         | 13/125 [00:50<07:18,  3.91s/it]\u001b[A\n",
            " 11%|█         | 14/125 [00:55<07:33,  4.09s/it]\u001b[A\n",
            " 12%|█▏        | 15/125 [00:58<07:14,  3.95s/it]\u001b[A\n",
            " 13%|█▎        | 16/125 [01:02<06:56,  3.82s/it]\u001b[A\n",
            " 14%|█▎        | 17/125 [01:07<07:24,  4.12s/it]\u001b[A\n",
            " 14%|█▍        | 18/125 [01:10<07:00,  3.93s/it]\u001b[A\n",
            " 15%|█▌        | 19/125 [01:14<06:41,  3.79s/it]\u001b[A\n",
            " 16%|█▌        | 20/125 [01:18<06:44,  3.85s/it]\u001b[A\n",
            " 17%|█▋        | 21/125 [01:22<06:56,  4.01s/it]\u001b[A\n",
            " 18%|█▊        | 22/125 [01:26<06:35,  3.84s/it]\u001b[A\n",
            " 18%|█▊        | 23/125 [01:29<06:22,  3.75s/it]\u001b[A\n",
            " 19%|█▉        | 24/125 [01:34<06:52,  4.09s/it]\u001b[A\n",
            " 20%|██        | 25/125 [01:37<06:32,  3.93s/it]\u001b[A\n",
            " 21%|██        | 26/125 [01:41<06:13,  3.78s/it]\u001b[A\n",
            " 22%|██▏       | 27/125 [01:45<06:08,  3.76s/it]\u001b[A\n",
            " 22%|██▏       | 28/125 [01:51<07:14,  4.48s/it]\u001b[A\n",
            " 23%|██▎       | 29/125 [01:55<06:53,  4.31s/it]\u001b[A\n",
            " 24%|██▍       | 30/125 [01:58<06:29,  4.10s/it]\u001b[A\n",
            " 25%|██▍       | 31/125 [02:03<06:35,  4.21s/it]\u001b[A\n",
            " 26%|██▌       | 32/125 [02:07<06:23,  4.13s/it]\u001b[A\n",
            " 26%|██▋       | 33/125 [02:10<06:02,  3.94s/it]\u001b[A\n",
            " 27%|██▋       | 34/125 [02:14<05:46,  3.81s/it]\u001b[A\n",
            " 28%|██▊       | 35/125 [02:19<06:13,  4.15s/it]\u001b[A\n",
            " 29%|██▉       | 36/125 [02:22<05:51,  3.95s/it]\u001b[A\n",
            " 30%|██▉       | 37/125 [02:26<05:36,  3.83s/it]\u001b[A\n",
            " 30%|███       | 38/125 [02:30<05:47,  3.99s/it]\u001b[A\n",
            " 31%|███       | 39/125 [02:34<05:45,  4.02s/it]\u001b[A\n",
            " 32%|███▏      | 40/125 [02:38<05:28,  3.86s/it]\u001b[A\n",
            " 33%|███▎      | 41/125 [02:41<05:15,  3.76s/it]\u001b[A\n",
            " 34%|███▎      | 42/125 [02:46<05:41,  4.12s/it]\u001b[A\n",
            " 34%|███▍      | 43/125 [02:50<05:22,  3.93s/it]\u001b[A\n",
            " 35%|███▌      | 44/125 [02:53<05:08,  3.81s/it]\u001b[A\n",
            " 36%|███▌      | 45/125 [02:57<05:10,  3.89s/it]\u001b[A\n",
            " 37%|███▋      | 46/125 [03:02<05:25,  4.13s/it]\u001b[A\n",
            " 38%|███▊      | 47/125 [03:05<05:09,  3.96s/it]\u001b[A\n",
            " 38%|███▊      | 48/125 [03:09<04:56,  3.85s/it]\u001b[A\n",
            " 39%|███▉      | 49/125 [03:14<05:19,  4.20s/it]\u001b[A\n",
            " 40%|████      | 50/125 [03:18<05:00,  4.01s/it]\u001b[A\n",
            " 41%|████      | 51/125 [03:21<04:45,  3.86s/it]\u001b[A\n",
            " 42%|████▏     | 52/125 [03:25<04:45,  3.91s/it]\u001b[A\n",
            " 42%|████▏     | 53/125 [03:30<04:56,  4.12s/it]\u001b[A\n",
            " 43%|████▎     | 54/125 [03:33<04:40,  3.95s/it]\u001b[A\n",
            " 44%|████▍     | 55/125 [03:37<04:28,  3.84s/it]\u001b[A\n",
            " 45%|████▍     | 56/125 [03:42<04:49,  4.20s/it]\u001b[A\n",
            " 46%|████▌     | 57/125 [03:46<04:33,  4.03s/it]\u001b[A\n",
            " 46%|████▋     | 58/125 [03:49<04:20,  3.89s/it]\u001b[A\n",
            " 47%|████▋     | 59/125 [03:53<04:16,  3.89s/it]\u001b[A\n",
            " 48%|████▊     | 60/125 [03:58<04:30,  4.16s/it]\u001b[A\n",
            " 49%|████▉     | 61/125 [04:02<04:20,  4.06s/it]\u001b[A\n",
            " 50%|████▉     | 62/125 [04:05<04:07,  3.93s/it]\u001b[A\n",
            " 50%|█████     | 63/125 [04:11<04:30,  4.37s/it]\u001b[A\n",
            " 51%|█████     | 64/125 [04:15<04:31,  4.46s/it]\u001b[A\n",
            " 52%|█████▏    | 65/125 [04:19<04:11,  4.19s/it]\u001b[A\n",
            " 53%|█████▎    | 66/125 [04:23<04:12,  4.29s/it]\u001b[A\n",
            " 54%|█████▎    | 67/125 [04:28<04:06,  4.25s/it]\u001b[A\n",
            " 54%|█████▍    | 68/125 [04:31<03:50,  4.05s/it]\u001b[A\n",
            " 55%|█████▌    | 69/125 [04:35<03:38,  3.90s/it]\u001b[A\n",
            " 56%|█████▌    | 70/125 [04:40<03:52,  4.22s/it]\u001b[A\n",
            " 57%|█████▋    | 71/125 [04:43<03:36,  4.01s/it]\u001b[A\n",
            " 58%|█████▊    | 72/125 [04:47<03:25,  3.88s/it]\u001b[A\n",
            " 58%|█████▊    | 73/125 [04:51<03:29,  4.04s/it]\u001b[A\n",
            " 59%|█████▉    | 74/125 [04:55<03:27,  4.06s/it]\u001b[A\n",
            " 60%|██████    | 75/125 [04:59<03:16,  3.94s/it]\u001b[A\n",
            " 61%|██████    | 76/125 [05:03<03:08,  3.85s/it]\u001b[A\n",
            " 62%|██████▏   | 77/125 [05:08<03:21,  4.21s/it]\u001b[A\n",
            " 62%|██████▏   | 78/125 [05:11<03:08,  4.01s/it]\u001b[A\n",
            " 63%|██████▎   | 79/125 [05:15<02:57,  3.86s/it]\u001b[A\n",
            " 64%|██████▍   | 80/125 [05:19<03:00,  4.01s/it]\u001b[A\n",
            " 65%|██████▍   | 81/125 [05:23<02:57,  4.03s/it]\u001b[A\n",
            " 66%|██████▌   | 82/125 [05:27<02:47,  3.90s/it]\u001b[A\n",
            " 66%|██████▋   | 83/125 [05:30<02:38,  3.78s/it]\u001b[A\n",
            " 67%|██████▋   | 84/125 [05:35<02:49,  4.13s/it]\u001b[A\n",
            " 68%|██████▊   | 85/125 [05:39<02:38,  3.96s/it]\u001b[A\n",
            " 69%|██████▉   | 86/125 [05:42<02:29,  3.82s/it]\u001b[A\n",
            " 70%|██████▉   | 87/125 [05:47<02:29,  3.95s/it]\u001b[A\n",
            " 70%|███████   | 88/125 [05:51<02:29,  4.03s/it]\u001b[A\n",
            " 71%|███████   | 89/125 [05:54<02:18,  3.84s/it]\u001b[A\n",
            " 72%|███████▏  | 90/125 [05:58<02:11,  3.76s/it]\u001b[A\n",
            " 73%|███████▎  | 91/125 [06:03<02:20,  4.13s/it]\u001b[A\n",
            " 74%|███████▎  | 92/125 [06:06<02:11,  3.97s/it]\u001b[A\n",
            " 74%|███████▍  | 93/125 [06:10<02:02,  3.83s/it]\u001b[A\n",
            " 75%|███████▌  | 94/125 [06:16<02:19,  4.49s/it]\u001b[A\n",
            " 76%|███████▌  | 95/125 [06:20<02:10,  4.35s/it]\u001b[A\n",
            " 77%|███████▋  | 96/125 [06:23<01:59,  4.11s/it]\u001b[A\n",
            " 78%|███████▊  | 97/125 [06:27<01:50,  3.96s/it]\u001b[A\n",
            " 78%|███████▊  | 98/125 [06:32<01:57,  4.33s/it]\u001b[A\n",
            " 79%|███████▉  | 99/125 [06:37<01:55,  4.46s/it]\u001b[A\n",
            " 80%|████████  | 100/125 [06:41<01:44,  4.19s/it]\u001b[A\n",
            " 81%|████████  | 101/125 [06:45<01:45,  4.41s/it]\u001b[A\n",
            " 82%|████████▏ | 102/125 [06:49<01:35,  4.15s/it]\u001b[A\n",
            " 82%|████████▏ | 103/125 [06:52<01:26,  3.95s/it]\u001b[A\n",
            " 83%|████████▎ | 104/125 [06:57<01:23,  3.98s/it]\u001b[A\n",
            " 84%|████████▍ | 105/125 [07:01<01:22,  4.11s/it]\u001b[A\n",
            " 85%|████████▍ | 106/125 [07:05<01:15,  3.97s/it]\u001b[A\n",
            " 86%|████████▌ | 107/125 [07:08<01:09,  3.86s/it]\u001b[A\n",
            " 86%|████████▋ | 108/125 [07:13<01:11,  4.18s/it]\u001b[A\n",
            " 87%|████████▋ | 109/125 [07:17<01:03,  3.99s/it]\u001b[A\n",
            " 88%|████████▊ | 110/125 [07:20<00:57,  3.84s/it]\u001b[A\n",
            " 89%|████████▉ | 111/125 [07:24<00:53,  3.84s/it]\u001b[A\n",
            " 90%|████████▉ | 112/125 [07:29<00:53,  4.09s/it]\u001b[A\n",
            " 90%|█████████ | 113/125 [07:32<00:46,  3.92s/it]\u001b[A\n",
            " 91%|█████████ | 114/125 [07:36<00:41,  3.80s/it]\u001b[A\n",
            " 92%|█████████▏| 115/125 [07:41<00:41,  4.11s/it]\u001b[A\n",
            " 93%|█████████▎| 116/125 [07:44<00:35,  3.97s/it]\u001b[A\n",
            " 94%|█████████▎| 117/125 [07:48<00:30,  3.83s/it]\u001b[A\n",
            " 94%|█████████▍| 118/125 [07:51<00:26,  3.79s/it]\u001b[A\n",
            " 95%|█████████▌| 119/125 [07:56<00:24,  4.08s/it]\u001b[A\n",
            " 96%|█████████▌| 120/125 [08:00<00:19,  3.92s/it]\u001b[A\n",
            " 97%|█████████▋| 121/125 [08:03<00:15,  3.80s/it]\u001b[A\n",
            " 98%|█████████▊| 122/125 [08:08<00:12,  4.09s/it]\u001b[A\n",
            " 98%|█████████▊| 123/125 [08:12<00:08,  4.04s/it]\u001b[A\n",
            " 99%|█████████▉| 124/125 [08:16<00:03,  3.92s/it]\u001b[A\n",
            "100%|██████████| 125/125 [08:19<00:00,  4.00s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval loss after 600 steps is 0.0617\n",
            "Final Correlation after 600 steps is 0.4546\n",
            "Saving model since validation loss reduced\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'suppress_tokens': []}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
            " 19%|█▉        | 600/3125 [4:52:17<129:58:10, 185.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 600 is 0.0080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 610/3125 [4:55:16<15:33:44, 22.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 610 is 0.0750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 620/3125 [4:58:14<12:25:52, 17.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss at step 620 is 0.0414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 624/3125 [4:59:28<20:00:19, 28.80s/it]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Sizes of tensors must match except in dimension 1. Expected size 4 but got size 8 for tensor number 2 in the list.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-df48ff2da32d>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every_n_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_no_improvement_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_deepspeed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-a731c43ff989>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, encoder, dataloader_train, dataloader_val, optimizer, scheduler, criterion, epochs, eval_every_n_steps, max_no_improvement_evals, save_path, is_deepspeed)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids_mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_mqm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-d48c5554d402>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids_src, input_ids_mt, input_ids_ref)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0;31m# Concatenate pooled representations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m           combined_pooled = torch.cat([\n\u001b[0m\u001b[1;32m     72\u001b[0m               \u001b[0mmt_pooled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m               \u001b[0mref_pooled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 4 but got size 8 for tensor number 2 in the list."
          ]
        }
      ],
      "source": [
        "#Logging wandb\n",
        "import wandb\n",
        "wandb.init(project=\"New Indicrun\", settings=wandb.Settings(start_method=\"fork\"))\n",
        "\n",
        "# Log configuration parameters\n",
        "wandb.config.update({\n",
        "\n",
        "    \"model_name\": model_name,\n",
        "    \"max_length\": max_length,\n",
        "    \"attention_dropout\": attention_dropout,\n",
        "    \"hidden_dropout\": hidden_dropout,\n",
        "    \"activation_dropout\": activation_dropout,\n",
        "    \"train_batch_size\": train_batch_size,\n",
        "    \"val_batch_size\": val_batch_size,\n",
        "    \"r\": r,\n",
        "    \"lora_alpha\": lora_alpha,\n",
        "    \"target_modules\": target_modules,\n",
        "    \"lora_dropout\": lora_dropout,\n",
        "    \"lr\": lr,\n",
        "    \"epochs\": epochs,\n",
        "    \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
        "    \"use_8bit_adam\": use_8bit_adam,\n",
        "    \"criterion\": str(criterion),\n",
        "    \"eval_every_n_steps\": eval_every_n_steps,\n",
        "    \"max_no_improvement_evals\": max_no_improvement_evals,\n",
        "    \"save_path\": save_path,\n",
        "    \"is_deepspeed\": is_deepspeed,\n",
        "    \"lora\": lora,\n",
        "    \"pooling_logic\": pooling_logic\n",
        "\n",
        "})\n",
        "\n",
        "# Main\n",
        "print(\"Loading datasets...\")\n",
        "df_train = load_dataset(dataset_train_path)\n",
        "df_val = load_dataset(dataset_val_path)\n",
        "\n",
        "print(\"Loading encoder and tokenizer...\")\n",
        "encoder, tokenizer=load_model(model_name, random_init=False, hidden_dropout=hidden_dropout)\n",
        "\n",
        "print(\"Preparing datasets and merging them...\")\n",
        "dataset_train = prepare_dataset(df_train, encoder, tokenizer, max_length)\n",
        "dataset_val = prepare_dataset(df_val, encoder, tokenizer, max_length)\n",
        "\n",
        "print(\"Creating dataloaders...\")\n",
        "dataloader_train, dataloader_val = create_dataloader(dataset_train, dataset_val, tokenizer, train_batch_size, val_batch_size)\n",
        "\n",
        "print(\"Loading model...\")\n",
        "model = XLMRForRegression(tokenizer, train_batch_size, pooling_logic=\"layerwise_attention_mean\", pool_output=True)\n",
        "\n",
        "if lora:\n",
        "        print(\"Converting to LoRA...\")\n",
        "        model = convert_to_lora(model, r, lora_alpha, target_modules, lora_dropout)\n",
        "\n",
        "print(\"Getting optimizer and scheduler...\")\n",
        "optimizer, scheduler, num_steps, warmup_steps = get_optimizer_scheduler(model, lr, epochs, dataloader_train, gradient_accumulation_steps, use_8bit_adam)\n",
        "# optimizer, scheduler, num_steps = get_optimizer_scheduler(model, lr, epochs, dataloader_train)\n",
        "\n",
        "print(\"Training...\")\n",
        "train(model, encoder, dataloader_train, dataloader_val, optimizer, scheduler, criterion, epochs=epochs, eval_every_n_steps=50, max_no_improvement_evals=3, save_path=save_path, is_deepspeed=False)\n",
        "\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATCzxXFxozBQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
